<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>StriveZs的博客</title>
  
  <subtitle>Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="www.strivezs.com/"/>
  <updated>2020-07-12T14:15:17.830Z</updated>
  <id>www.strivezs.com/</id>
  
  <author>
    <name>StriveZs</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PHP+XML+DTD+HTML 编写的在线词典</title>
    <link href="www.strivezs.com/2020/07/12/PHP+XML+DTD+HTML%20%E7%BC%96%E5%86%99%E7%9A%84%E5%9C%A8%E7%BA%BF%E8%AF%8D%E5%85%B8/"/>
    <id>www.strivezs.com/2020/07/12/PHP+XML+DTD+HTML%20%E7%BC%96%E5%86%99%E7%9A%84%E5%9C%A8%E7%BA%BF%E8%AF%8D%E5%85%B8/</id>
    <published>2020-07-12T14:15:17.830Z</published>
    <updated>2020-07-12T14:15:17.830Z</updated>
    
    <content type="html"><![CDATA[<h1>PHP+XML+DTD+HTML 编写的在线词典</h1><h2 id="view"><a class="header-anchor" href="#view">¶</a>view</h2><h3 id="主界面"><a class="header-anchor" href="#主界面">¶</a>主界面</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>操作页面<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>查询单词<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/study/XML学习/词典系统/control/search.php"</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span></span><br><span class="line">        输入你要查询的英文的单词: <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"english"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"查询"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h1</span>&gt;</span>添加单词<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/XML学习/词典系统/control/addDict.php"</span> <span class="attr">method</span>=<span class="string">"post"</span>&gt;</span></span><br><span class="line">        英文: <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"eng"</span>&gt;</span></span><br><span class="line">        中文: <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"chi"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">value</span>=<span class="string">"提交"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="查询成功界面"><a class="header-anchor" href="#查询成功界面">¶</a>查询成功界面</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>查询结果页面<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>查询结果为<span class="php"><span class="meta">&lt;?php</span> <span class="keyword">echo</span> $_GET[<span class="string">'chinese'</span>]; <span class="meta">?&gt;</span></span><span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="查询失败界面"><a class="header-anchor" href="#查询失败界面">¶</a>查询失败界面</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>查询结果失败页面<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>没有该单词!<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="control"><a class="header-anchor" href="#control">¶</a>control</h2><h3 id="查询单词"><a class="header-anchor" href="#查询单词">¶</a>查询单词</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="php"><span class="meta">&lt;?php</span></span></span><br><span class="line"><span class="php">    <span class="function"><span class="keyword">function</span> <span class="title">getNodeValue</span><span class="params">(&amp;$myNode,$tagName)</span></span>&#123;</span></span><br><span class="line"><span class="php">        <span class="keyword">return</span> $myNode-&gt;getElementsByTagName($tagName)-&gt;item(<span class="number">0</span>)-&gt;nodeValue;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="php">    $word = $_POST[<span class="string">'english'</span>];</span></span><br><span class="line"></span><br><span class="line"><span class="php">    <span class="comment">// 创建DOCDocument对象</span></span></span><br><span class="line"><span class="php">    $xmlDoc = <span class="keyword">new</span> DOMDocument();</span></span><br><span class="line"><span class="php">    <span class="comment">// 加载xml文件</span></span></span><br><span class="line"><span class="php">    $xmlDoc-&gt;load(<span class="string">"/XML学习/词典系统/model/dict.xml"</span>);</span></span><br><span class="line"><span class="php">    <span class="comment">// 查询单词</span></span></span><br><span class="line"><span class="php">    $wordList = $xmlDoc-&gt;getElementsByTagName(<span class="string">"单词"</span>);</span></span><br><span class="line"><span class="php">    $index = <span class="number">-1</span>;</span></span><br><span class="line"><span class="php">    <span class="keyword">for</span>($i=<span class="number">0</span>;$i&lt;$wordList-&gt;length;$i++)&#123;</span></span><br><span class="line"><span class="php">        $result = getNodeValue($wordList[$i],<span class="string">"英文"</span>);</span></span><br><span class="line"><span class="php">        <span class="keyword">if</span>($result == $word)&#123;</span></span><br><span class="line"><span class="php">            $index = $i;</span></span><br><span class="line"><span class="php">            <span class="keyword">break</span>;</span></span><br><span class="line"><span class="php">        &#125;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php">    <span class="keyword">if</span>($index == <span class="number">-1</span>)&#123;</span></span><br><span class="line"><span class="php">        header(<span class="string">"Location:/XML学习/词典系统/view/failed.html"</span>);</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php">    <span class="keyword">else</span>&#123;</span></span><br><span class="line"><span class="php">        $chinese= getNodeValue($wordList[$index],<span class="string">"中文"</span>);</span></span><br><span class="line"><span class="php">        $encode = urlencode($chinese);</span></span><br><span class="line"><span class="php">        header(<span class="string">"Location:/XML学习/词典系统/view/mess.php?chinese=$encode"</span>);</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"></span><br><span class="line"><span class="php"><span class="meta">?&gt;</span></span></span><br></pre></td></tr></table></figure><h3 id="添加单词"><a class="header-anchor" href="#添加单词">¶</a>添加单词</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="php"><span class="meta">&lt;?php</span></span></span><br><span class="line"><span class="php">    <span class="function"><span class="keyword">function</span> <span class="title">getNodeValue</span><span class="params">(&amp;$myNode,$tagName)</span></span>&#123;</span></span><br><span class="line"><span class="php">        <span class="keyword">return</span> $myNode-&gt;getElementsByTagName($tagName)-&gt;item(<span class="number">0</span>)-&gt;nodeValue;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php">    $eng = $_POST[<span class="string">'eng'</span>];</span></span><br><span class="line"><span class="php">    $chi = $_POST[<span class="string">'chi'</span>];</span></span><br><span class="line"></span><br><span class="line"><span class="php">    <span class="comment">// 先判断单词是否存在，如果存在则不添加，并提示</span></span></span><br><span class="line"><span class="php">    <span class="comment">// 创建DOCDocument对象</span></span></span><br><span class="line"><span class="php">    $xmlDoc = <span class="keyword">new</span> DOMDocument();</span></span><br><span class="line"><span class="php">    <span class="comment">// 加载xml文件</span></span></span><br><span class="line"><span class="php">    $xmlDoc-&gt;load(<span class="string">"/XML学习/词典系统/model/dict.xml"</span>);</span></span><br><span class="line"><span class="php">    <span class="comment">// 查询单词</span></span></span><br><span class="line"><span class="php">    $wordList = $xmlDoc-&gt;getElementsByTagName(<span class="string">"单词"</span>);</span></span><br><span class="line"><span class="php">    $index = <span class="number">-1</span>;</span></span><br><span class="line"><span class="php">    <span class="keyword">for</span>($i=<span class="number">0</span>;$i&lt;$wordList-&gt;length;$i++)&#123;</span></span><br><span class="line"><span class="php">        $result = getNodeValue($wordList[$i],<span class="string">"英文"</span>);</span></span><br><span class="line"><span class="php">        <span class="keyword">if</span>($result == $eng)&#123;</span></span><br><span class="line"><span class="php">            $index = $i;</span></span><br><span class="line"><span class="php">            <span class="keyword">break</span>;</span></span><br><span class="line"><span class="php">        &#125;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php">    <span class="keyword">if</span>($index != <span class="number">-1</span>)&#123;</span></span><br><span class="line"><span class="php">        <span class="keyword">echo</span> <span class="string">"&lt;script&gt;window.alert('单词已经存在! 添加失败');history.back();&lt;/script&gt;"</span>;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php">    <span class="keyword">else</span>&#123;</span></span><br><span class="line"><span class="php">        <span class="comment">// 得到根节点n</span></span></span><br><span class="line"><span class="php">        $root = $xmlDoc-&gt;getElementsByTagName(<span class="string">"词典"</span>)-&gt;item(<span class="number">0</span>);</span></span><br><span class="line"><span class="php">        <span class="comment">// 创建单词节点</span></span></span><br><span class="line"><span class="php">        $new_word = $xmlDoc-&gt;createElement(<span class="string">"单词"</span>);</span></span><br><span class="line"><span class="php">        <span class="comment">// 创建中文节点</span></span></span><br><span class="line"><span class="php">        $new_chi = $xmlDoc-&gt;createElement(<span class="string">"中文"</span>);</span></span><br><span class="line"><span class="php">        $new_chi-&gt;nodeValue = $chi;</span></span><br><span class="line"><span class="php">        <span class="comment">// 创建英文节点</span></span></span><br><span class="line"><span class="php">        $new_eng = $xmlDoc-&gt;createElement(<span class="string">"英文"</span>);</span></span><br><span class="line"><span class="php">        $new_eng-&gt;nodeValue = $eng;</span></span><br><span class="line"></span><br><span class="line"><span class="php">        <span class="comment">// 将节点挂载</span></span></span><br><span class="line"><span class="php">        $new_word-&gt;appendChild($new_eng);</span></span><br><span class="line"><span class="php">        $new_word-&gt;appendChild($new_chi);</span></span><br><span class="line"><span class="php">        $root-&gt;appendChild($new_word);</span></span><br><span class="line"></span><br><span class="line"><span class="php">        <span class="comment">// 保存xml文件</span></span></span><br><span class="line"><span class="php">        $xmlDoc-&gt;save(<span class="string">"/个人文件/study/XML学习/词典系统/model/dict.xml"</span>);</span></span><br><span class="line"><span class="php">        <span class="keyword">echo</span> <span class="string">"&lt;script&gt;window.alert('单词保存成功!');history.back();&lt;/script&gt;"</span>;</span></span><br><span class="line"><span class="php">    &#125;</span></span><br><span class="line"><span class="php"><span class="meta">?&gt;</span></span></span><br></pre></td></tr></table></figure><h2 id="model"><a class="header-anchor" href="#model">¶</a>model</h2><h3 id="存储单词文件"><a class="header-anchor" href="#存储单词文件">¶</a>存储单词文件</h3><p>xml文件</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE 词典 <span class="meta-keyword">SYSTEM</span> <span class="meta-string">"dict.dtd"</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--引入dtd文件--&gt;</span></span><br><span class="line"><span class="comment">&lt;!--班级 根元素--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">词典</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">单词</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">英文</span>&gt;</span>boy<span class="tag">&lt;/<span class="name">英文</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">中文</span>&gt;</span>男孩<span class="tag">&lt;/<span class="name">中文</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">单词</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">单词</span>&gt;</span><span class="tag">&lt;<span class="name">英文</span>&gt;</span>girls<span class="tag">&lt;/<span class="name">英文</span>&gt;</span><span class="tag">&lt;<span class="name">中文</span>&gt;</span>女孩<span class="tag">&lt;/<span class="name">中文</span>&gt;</span><span class="tag">&lt;/<span class="name">单词</span>&gt;</span><span class="tag">&lt;/<span class="name">词典</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="DTD文件"><a class="header-anchor" href="#DTD文件">¶</a>DTD文件</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!ELEMENT 词典 (单词+)&gt;</span></span><br><span class="line">    <span class="meta">&lt;!ELEMENT 单词 (英文,中文)&gt;</span></span><br><span class="line">        <span class="meta">&lt;!ELEMENT 英文 (<span class="meta-keyword">#PCDATA</span>)&gt;</span></span><br><span class="line">        <span class="meta">&lt;!ELEMENT 中文 (<span class="meta-keyword">#PCDATA</span>)&gt;</span></span><br></pre></td></tr></table></figure><h2 id="展示"><a class="header-anchor" href="#展示">¶</a>展示</h2><p><img src="https://gitee.com/zyp521/upload_image/raw/master/NkX3bj.png" alt="figure.1"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/ilIfqN.png" alt="figure.2"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/hjVnNG.png" alt="figure.3"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/wKh5qo.png" alt="figure.4"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/JI4NdI.png" alt="figure.5"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1&gt;PHP+XML+DTD+HTML 编写的在线词典&lt;/h1&gt;
&lt;h2 id=&quot;view&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#view&quot;&gt;¶&lt;/a&gt;view&lt;/h2&gt;
&lt;h3 id=&quot;主界面&quot;&gt;&lt;a class=&quot;header-anchor&quot; h
      
    
    </summary>
    
    
      <category term="PHP" scheme="www.strivezs.com/categories/PHP/"/>
    
      <category term="XML" scheme="www.strivezs.com/categories/PHP/XML/"/>
    
    
      <category term="PHP" scheme="www.strivezs.com/tags/PHP/"/>
    
      <category term="XML" scheme="www.strivezs.com/tags/XML/"/>
    
      <category term="DTD" scheme="www.strivezs.com/tags/DTD/"/>
    
      <category term="词典" scheme="www.strivezs.com/tags/%E8%AF%8D%E5%85%B8/"/>
    
  </entry>
  
  <entry>
    <title>Non-Maximum Suppression(NMS)</title>
    <link href="www.strivezs.com/2020/07/08/Non-Maximum%20Suppression(NMS)%20%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6/"/>
    <id>www.strivezs.com/2020/07/08/Non-Maximum%20Suppression(NMS)%20%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6/</id>
    <published>2020-07-08T04:39:22.949Z</published>
    <updated>2020-07-08T04:39:22.949Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Non-Maximum-Suppression-NMS-非极大值抑制"><a href="#Non-Maximum-Suppression-NMS-非极大值抑制" class="headerlink" title="Non-Maximum Suppression(NMS) 非极大值抑制"></a>Non-Maximum Suppression(NMS) 非极大值抑制</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>非极大值抑制(NMS), 顾名思义就是抑制不是极大值的元素，可以理解为局部最大搜索。这个局部代表的就是一个邻域，邻域有两个参数可变，一个是邻域的维数，而是邻域的大小。这里不讨论通用的NMS算法, 而是用于目标检测中提取分数最高的窗口。  </p><p>例如在行人检测中，滑动窗口经提取特征，经分类器识别后，每个窗口都会得到一个分数。但是滑动窗口会导致很多窗口和其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取这些邻域里分数最高(是行人几率最大)，并且一直那些分数低的窗口。  </p><p>NMS在计算视觉领域有着非常重要的应用，如视频目标跟踪、数据挖掘、3D重建、目标识别以及纹理分析等。</p><h2 id="NMS在目标检测中的应用"><a href="#NMS在目标检测中的应用" class="headerlink" title="NMS在目标检测中的应用"></a>NMS在目标检测中的应用</h2><h3 id="人脸检测框重叠例子"><a href="#人脸检测框重叠例子" class="headerlink" title="人脸检测框重叠例子"></a>人脸检测框重叠例子</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/bWa7my.png" alt="figure.1"></p><p>我们的目标就是要去除冗余的检测框，保留最好的一个。<br>有多种方式可以解决这个问题，Triggs建议使用<strong>Mean-shift</strong>算法，利用bbox的坐标和当前图片尺度的对数来检测bbox的多种模式，但是效果可能并没有使用强分类器结合NMS的效果好。  </p><h3 id="检测目标-pipline"><a href="#检测目标-pipline" class="headerlink" title="检测目标 pipline"></a>检测目标 pipline</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/RKmAqi.png" alt="figure.2"></p><p>产生proposal后使用分类网络给吃每个框的每类置信度，使用回归网路修正位置，最终应用NMS。</p><h2 id="NMS原理"><a href="#NMS原理" class="headerlink" title="NMS原理"></a>NMS原理</h2><p>对于Bounding Box的列表B以及对应的置信度S，采用下面的计算方式，选择具有最大score的检测框M，将其从B集合中移除并加入到最终的检测结果D中，通常将B中剩余检测框中与M的IoU大于阈值Nt的框从B中移除，重复这个过程，直到B为空。</p><h3 id="IoU阈值和排序"><a href="#IoU阈值和排序" class="headerlink" title="IoU阈值和排序"></a>IoU阈值和排序</h3><p>通常阈值设置是0.3-0.5<br>其中用到的排序，可以按照右下角的坐标排序或者面积排序，也可以通过SVM等分类器得到的得分或者概率，<strong>R-CNN中就是按照得分进行排序的</strong>.  </p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/dF8ON9.png" alt="figure.3"></p><p>如上面图片所示，定位一个车辆，最后算法就找出了一堆方框，我们需要判别哪些矩形框是没用的，<br>非极大值抑制的方法是: 假设有6个矩形框，根据分类器的类别分类概率做排序，假设从小到大属于车辆的概率，分别为A、B、C、D、E、F。  </p><ul><li>从最大概率矩形框F开始，分别判断A-E与F的重叠率IoU是否大于某个设定的阈值</li><li>假设B、D和F的重叠度超过了阈值，那么就扔掉B、D；并表卷积第一个矩形框F，是我们保留下来的。</li><li>从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E和A、C的重叠度，重叠度大于阈值的就扔掉，将标记E是我们保留下来的第二个矩形框</li><li>就这样重复上述步骤，直到剩余框集合中没有元素了，那么被保留下来的矩形框就是我们所需要的定位框。</li></ul><h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p>在R-CNN中使用了NMS来确定最终的bounding-box，其对应每个候选框分别送入分类器，根据分类器的类别分类概率进行排序(greedy-NMS)， 但实际也可以在分类之前运用简单版本的NMS来去除一些框。  </p><p>Python实现单类别的NMS:<br><figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">def py_cpu_nms(dets, thresh): </span><br><span class="line">    <span class="string">""</span><span class="string">"Pure Python NMS baseline."</span><span class="string">""</span> </span><br><span class="line">    <span class="comment">#x1、y1、x2、y2、以及score赋值 </span></span><br><span class="line">    <span class="attr">x1</span> = dets[:, <span class="number">0</span>] </span><br><span class="line">    <span class="attr">y1</span> = dets[:, <span class="number">1</span>] </span><br><span class="line">    <span class="attr">x2</span> = dets[:, <span class="number">2</span>] </span><br><span class="line">    <span class="attr">y2</span> = dets[:, <span class="number">3</span>] </span><br><span class="line">    <span class="attr">scores</span> = dets[:, <span class="number">4</span>] </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#每一个检测框的面积 </span></span><br><span class="line">    <span class="attr">areas</span> = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>) </span><br><span class="line">    <span class="comment">#按照score置信度降序排序 </span></span><br><span class="line">    <span class="attr">order</span> = scores.argsort()[::-<span class="number">1</span>] </span><br><span class="line">    <span class="attr">keep</span> = [] </span><br><span class="line">    <span class="comment">#保留的结果框集合 </span></span><br><span class="line">    while order.size &gt; <span class="number">0</span>: </span><br><span class="line">        <span class="attr">i</span> = order[<span class="number">0</span>] </span><br><span class="line">        keep.append(i) </span><br><span class="line">        <span class="comment">#保留该类剩余box中得分最高的一个 </span></span><br><span class="line">        <span class="comment">#得到相交区域,左上及右下 </span></span><br><span class="line">        <span class="attr">xx1</span> = np.maximum(x1[i], x1[order[<span class="number">1</span>:]]) <span class="attr">yy1</span> = np.maximum(y1[i], y1[order[<span class="number">1</span>:]]) </span><br><span class="line">        <span class="attr">xx2</span> = np.minimum(x2[i], x2[order[<span class="number">1</span>:]]) <span class="attr">yy2</span> = np.minimum(y2[i], y2[order[<span class="number">1</span>:]]) <span class="comment">#计算相交的面积,不重叠时面积为0 </span></span><br><span class="line">        <span class="attr">w</span> = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>) </span><br><span class="line">        <span class="attr">h</span> = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>) <span class="attr">inter</span> = w * h <span class="comment">#计算IoU：重叠面积 /（面积1+面积2-重叠面积） </span></span><br><span class="line">        <span class="attr">ovr</span> = inter / (areas[i] + areas[order[<span class="number">1</span>:]] - inter) <span class="comment">#保留IoU小于阈值的box </span></span><br><span class="line">        <span class="attr">inds</span> = np.where(ovr &lt;= thresh)[<span class="number">0</span>] </span><br><span class="line">        <span class="attr">order</span> = order[inds + <span class="number">1</span>] <span class="comment">#因为ovr数组的长度比order数组少一个,所以这里要将所有下标后移一位 </span></span><br><span class="line">    return keep</span><br></pre></td></tr></table></figure></p><p>Faster R-CNN的MATLAB和python版本实现一致，对于对类别的NMS，就是加了一层for循环来对每个类别进行NMS而已。</p><h3 id="NMS-Loss"><a href="#NMS-Loss" class="headerlink" title="NMS Loss"></a>NMS Loss</h3><p>值得注意的是对多类别检测任务，如果对每类进行NMS，那么当检测结果中包含两个被分到不同的目标且其IoU较大时，会得到不可接受的结果，如下图所示:</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Fd380c.png" alt="figure.4"></p><p>一种改进方式便是在损失函数中加入一部分NMS损失。NMS损失可以定义为与分类损失相同：<script type="math/tex">L_{nms}=L_{cls}(p,u)=-log_{p_{u}}</script>, 即真实类别u对应log损失，p是C个类别的预测概率，实际相当于增加分类误差。</p><h3 id="Sotf-NMS"><a href="#Sotf-NMS" class="headerlink" title="Sotf-NMS"></a>Sotf-NMS</h3><p>上述NMS算法的一个主要问题是当两个ground-truth的目标的重叠度很高时，NMS会将具有较低置信度的去掉, 如下图所示：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/1SliMR.png" alt="figure.5"></p><p>如上图所示，红框和绿框的重叠度很大，应该超过了一般大家所设定的阈值，因此在NMS算法中由于绿框的置信度为0.8而红框为0.95，因此NMS算法会将绿框去掉，这样是不正确的。  </p><p>在Soft-NMS中对NMS这个缺陷进行改进：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/kSvvcn.png" alt="figure.6"></p><p>改进方法在于将置信度改为IoU的函数: f(IoU)，具有较低的值而不至于从排序列表中删去。</p><p>两种形式的IoU函数:</p><ul><li>线性函数：即将需要取出的框的置信度改为1-重叠值, 函数值不连续，在某一点的值发生跳跃</li></ul><script type="math/tex; mode=display">s_{i}=\left\{\begin{matrix} s_{i}\:\:\:\:iou(M,b_{i})<N_{t} \\ s_{i}(1-iou(M,b_{i}))\:\:\:\: iou(M,b_{i}) \geq N_{t} \end{matrix}\right.</script><ul><li>高斯函数，时间复杂度同传统的greedy-NMS, 为<script type="math/tex">\sigma (N^{2})</script></li></ul><script type="math/tex; mode=display">s_{i}=s_{i}e \frac{-iou(M,b_{i}^{2})}{\sigma},\forall b_{i} \notin D</script><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ua = float((tx2 - tx1 + <span class="number">1</span>) * (ty2 - ty1 + <span class="number">1</span>) + area - iw * ih) ov = iw * ih / ua #iou between max box <span class="keyword">and</span> detection box </span><br><span class="line"><span class="keyword">if</span> <span class="function"><span class="keyword">method</span> == 1:</span> # linear </span><br><span class="line">    <span class="keyword">if</span> ov &gt; Nt: </span><br><span class="line">        weight = <span class="number">1</span> - ov </span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        weight = <span class="number">1</span> </span><br><span class="line">elif <span class="function"><span class="keyword">method</span> == 2:</span> # gaussian </span><br><span class="line">    weight = np.exp(-(ov * ov)/sigma) </span><br><span class="line"><span class="keyword">else</span>: # original NMS </span><br><span class="line">    <span class="keyword">if</span> ov &gt; Nt: </span><br><span class="line">        weight = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        weight = <span class="number">1</span> </span><br><span class="line">        </span><br><span class="line"># re-scoring 修改置信度 </span><br><span class="line">boxes[pos, <span class="number">4</span>] = weight*boxes[pos, <span class="number">4</span>]</span><br></pre></td></tr></table></figure><p>基于proposal方法的模型结果上应用比较好，检测效果提升:</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/6qkPNP.png" alt="figure.7"></p><p>在R-FCN以及Faster R-CNN模型中的测试阶段运用Soft-NMS，在MS-COCO数据集上能够获得大约1%的提升。如果应用到训练阶段的proposal选取过程理论上也能获得提升，在自己的实验中发现确实对易重叠的目标类型有提高(目标不一定真在像素上重叠，切斜的目标的矩形边框会有较大的重叠)，而在SSD、YOLO等非proposal方法中没有提升。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Non-Maximum-Suppression-NMS-非极大值抑制&quot;&gt;&lt;a href=&quot;#Non-Maximum-Suppression-NMS-非极大值抑制&quot; class=&quot;headerlink&quot; title=&quot;Non-Maximum Suppression(
      
    
    </summary>
    
    
      <category term="Object Recognition" scheme="www.strivezs.com/categories/Object-Recognition/"/>
    
      <category term="Object Detection" scheme="www.strivezs.com/categories/Object-Recognition/Object-Detection/"/>
    
      <category term="科研" scheme="www.strivezs.com/categories/Object-Recognition/Object-Detection/%E7%A7%91%E7%A0%94/"/>
    
    
      <category term="NMS" scheme="www.strivezs.com/tags/NMS/"/>
    
      <category term="非极大值抑制" scheme="www.strivezs.com/tags/%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>IOU</title>
    <link href="www.strivezs.com/2020/07/01/IOU(%E9%87%8D%E5%8F%A0%E5%BA%A6)/"/>
    <id>www.strivezs.com/2020/07/01/IOU(%E9%87%8D%E5%8F%A0%E5%BA%A6)/</id>
    <published>2020-07-01T05:38:29.043Z</published>
    <updated>2020-07-01T05:38:29.043Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IOU"><a href="#IOU" class="headerlink" title="IOU"></a>IOU</h1><p>物体检测需要定位出物体的bounding box, 就像下面的图片一样，我们不仅要定位出车辆的bounding box，我们还要识别出bounding box里面的无力就是车辆.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/tklIHI.png" alt="figure.1"></p><p>对于bounding box的定位精度，有一个重要的概念：因为我们算法不可能百分百跟人工标注的数据完全匹配，因此就存在一个定位精度评价公式: IOU。  </p><p>它定义了两个bounding box的重叠度，如下图所示:  </p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/08cc3B.png" alt="figure.2"></p><p>就是矩形A、B的重叠面积占A、B并集的面积比例。</p><p>计算公式:</p><script type="math/tex; mode=display">IOU = \frac{A \cap B}{A \cup B}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;IOU&quot;&gt;&lt;a href=&quot;#IOU&quot; class=&quot;headerlink&quot; title=&quot;IOU&quot;&gt;&lt;/a&gt;IOU&lt;/h1&gt;&lt;p&gt;物体检测需要定位出物体的bounding box, 就像下面的图片一样，我们不仅要定位出车辆的bounding box，我们还要识别
      
    
    </summary>
    
    
      <category term="Object Recognition" scheme="www.strivezs.com/categories/Object-Recognition/"/>
    
      <category term="Object Detection" scheme="www.strivezs.com/categories/Object-Recognition/Object-Detection/"/>
    
    
      <category term="IOU" scheme="www.strivezs.com/tags/IOU/"/>
    
  </entry>
  
  <entry>
    <title>遗传算法（Genetic Algorithm）</title>
    <link href="www.strivezs.com/2020/06/28/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%EF%BC%88Genetic%20Algorithm%EF%BC%89/"/>
    <id>www.strivezs.com/2020/06/28/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%EF%BC%88Genetic%20Algorithm%EF%BC%89/</id>
    <published>2020-06-28T04:45:59.023Z</published>
    <updated>2020-06-28T04:45:59.023Z</updated>
    
    <content type="html"><![CDATA[<h1 id="遗传算法-（Genetic-Algorithm）"><a href="#遗传算法-（Genetic-Algorithm）" class="headerlink" title="遗传算法 （Genetic Algorithm）"></a>遗传算法 （Genetic Algorithm）</h1><h2 id="基础信息"><a href="#基础信息" class="headerlink" title="基础信息"></a>基础信息</h2><p><strong>选择策略：</strong> 物竞天择，适者生存。即按照某一特定条件进行选择。</p><p><strong>遗传因子:</strong> 在计算机中是用0/1编码来完成的</p><p><strong>遗传方式：</strong> 交叉、变异</p><h2 id="选择策略"><a href="#选择策略" class="headerlink" title="选择策略"></a>选择策略</h2><h3 id="轮盘赌选择法"><a href="#轮盘赌选择法" class="headerlink" title="轮盘赌选择法"></a>轮盘赌选择法</h3><p>轮盘赌选择法是根据个体的适应度值计算每个个体在子代中出现的概率，并按照此概率随机选择个体构成子代种群。</p><p><strong>常用步骤</strong> </p><ol><li>将种群中个体的适应度值叠加，其中m为种群个体数。<center> $$ \sum_{i=1}^{m}y(x_{i}) $$ </center></li><li>每个个体的适应度值除以总适应度值得到个体被选择的概率。</li><li>计算个体的累计概率以构造一个轮盘。</li><li>轮盘选择：产生一个[0,1]区间内的随机数，若该随机数小于或等于个体的累积概率，选择个体进入子代种群。</li></ol><p>重复上述步骤，即可得到一个由新个体构成的种群。</p><h3 id="随即遍历抽样法"><a href="#随即遍历抽样法" class="headerlink" title="随即遍历抽样法"></a>随即遍历抽样法</h3><p>像轮盘赌一样计算选择概率，只是在随机遍历选择中等距离的选择个体。设npoint为需要选择的个体数目，等距离的选择个体，选择指针的距离是 <script type="math/tex">[1,\frac{1}{npoint}]</script> ，第一个指针的位置由<script type="math/tex">[1,\frac{1}{npoint}]</script> 的均匀随机数决定。</p><h3 id="锦标赛选择法"><a href="#锦标赛选择法" class="headerlink" title="锦标赛选择法"></a>锦标赛选择法</h3><p>锦标赛选择法选择策略每次从种群中选取出一定数量个体，然后选择其中最好的一个进入子代种群。重复该操作直到新的种群规模到达原来种群规。</p><p><strong>步骤:</strong> </p><ol><li>确定每次选择的个体数量（百分比）</li><li>从种群中随机选择个体（每个概率相同）构成组，根据每个个体的适应度值，选择其中适应度值最好的个体进入子代种群。</li></ol><p>重复上述步骤，直到得到新一代种群。</p><h2 id="遗传算法编码"><a href="#遗传算法编码" class="headerlink" title="遗传算法编码"></a>遗传算法编码</h2><h3 id="二进制编码法"><a href="#二进制编码法" class="headerlink" title="二进制编码法"></a>二进制编码法</h3><p>就像人类的基因有AGCT四种碱基序列一样，不过在这里我们只用0和1两种碱基，然后将他们串成一条链来形成一条染色体，一个为能表示出2种状态的信息量，因此足够长的二进制染色体便能够表示所有的特征。</p><p>例如：111000110101</p><p><strong>优点：</strong></p><ol><li>编码、解码操作简单易行</li><li>交叉、变异等遗传操作便于实现</li><li>合最小字符集编码原则</li><li>利用模式定理对算法进行理论分析</li></ol><p><strong>缺点</strong></p><ol><li>高精度问题上面表现较差</li><li>容易陷入局部最优</li></ol><h3 id="浮点编码法"><a href="#浮点编码法" class="headerlink" title="浮点编码法"></a>浮点编码法</h3><p>二进制编码虽然简单直观，但明显地存在着连续函数离散化时的映射误差。个体长度较短时，可能达不到精度要求，而个体编码长度较长时，虽然能够提高精度，但增加了解码的难度，使遗传算法的搜索空间急剧扩大。</p><p><strong>浮点法：</strong> 是指个体的每个基因值用某一范围内的一个浮点数来表示。在浮点数码方法中，必须保证基因值在给定的区间限制范围内，遗传反中所使用的交叉、变异等遗传操作也必须保证其运算结果所产生的新个体的基因值也在这个区间限制范围内。</p><p>例如：1.2-3.2-5.3-7.2-1.4-9.7</p><p><strong>优点</strong></p><ol><li>适用于在遗传算法表示范围较大的数</li><li>适用于精度要求较高的遗传算法</li><li>便于较大空间的遗传搜索</li><li>改善了遗传算法的计算复杂性，提高了运算交率</li><li>便于遗传算法于经典优化方法的混合使用</li><li>便于设计针对问题的专门知识的知识型遗传算子</li><li>便于处理复杂的决策变量约束条件</li></ol><h3 id="符号编码法"><a href="#符号编码法" class="headerlink" title="符号编码法"></a>符号编码法</h3><p>符号编码是指个体染色体编码串中的基因值取自一个无数值含义、而只有代码含义的符号集如（A,B,C…）</p><p><strong>优点</strong></p><ol><li>符合有意义奇数块编码原则</li><li>便于在遗传算法中利用所求解问题的专门知识</li><li>便于遗传算法与相近似算法之间的混合使用</li></ol><h2 id="交叉"><a href="#交叉" class="headerlink" title="交叉"></a>交叉</h2><p><strong>交叉操作：</strong> 是指对两个相互配对的染色体按某种方式相互交换其余部分基因，从而形成两个新的个体。</p><h3 id="适用于二进制编码个体或浮点数编码个体的交叉算子："><a href="#适用于二进制编码个体或浮点数编码个体的交叉算子：" class="headerlink" title="适用于二进制编码个体或浮点数编码个体的交叉算子："></a>适用于二进制编码个体或浮点数编码个体的交叉算子：</h3><ol><li>单点交叉 (One-point Crossover):指在个体编码串中只随机设置一个交叉点，然后再该点相互交换两个配对个体的部分染色体。</li><li>两点交叉 (Two-point Crossover)：在个体编码串中随机设置了两个交叉点，然后在进行部分基因交换。</li><li>多点交叉 (Multi-point Crossover): 在个体编码串中随机选择多个交叉点，然后进行部分基因交换。</li><li>均匀交叉 (Uniform Corssover): 两个配对个体的每个基因座上的基因都以相同的交叉概率进行交换，从而形成两个新个体。</li><li>算数交叉 (Arithmetic Crossover): 由两个个体的线性组合而产生出两个新的个体，该操作对象一般是由浮点数编码表示的个体。</li></ol><h2 id="变异"><a href="#变异" class="headerlink" title="变异"></a>变异</h2><p>遗传算法中的变异运算，是指将个体染色体编码串中的某些基因座上的级音质用该基因座上的其他等位基因来替换，从而形成新的个体。</p><h3 id="适用于二进制编码和浮点数编码的个体："><a href="#适用于二进制编码和浮点数编码的个体：" class="headerlink" title="适用于二进制编码和浮点数编码的个体："></a>适用于二进制编码和浮点数编码的个体：</h3><ol><li>基本位变异 (Simple Mutation): 对个体编码串以变异概率、随即制定的某一位或某几位仅基因座上的值进行变异运算。</li><li>均匀变异 (Uniform Mutation): 分别用符合某一范围内均匀分布的随机数，以某一较小的概率来替换个体编码传中各个基因座上的原有基因值。</li><li>边界变异 (Boundary Mutation): 随机的取基因座上的两个对应边界基因值之一去替代原有基因值。</li><li>非均匀变异：对原有的基因值做一随机扰动，以扰动后的结果作为变异后的新的基因值。对每个基因座都以相同的概率进行变异运算之后，相当于整个解向量的解空间中做了一次轻微的变动。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;遗传算法-（Genetic-Algorithm）&quot;&gt;&lt;a href=&quot;#遗传算法-（Genetic-Algorithm）&quot; class=&quot;headerlink&quot; title=&quot;遗传算法 （Genetic Algorithm）&quot;&gt;&lt;/a&gt;遗传算法 （Genetic 
      
    
    </summary>
    
    
      <category term="人工智能" scheme="www.strivezs.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="进化算法" scheme="www.strivezs.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="GA" scheme="www.strivezs.com/tags/GA/"/>
    
  </entry>
  
  <entry>
    <title>极大似然估计</title>
    <link href="www.strivezs.com/2020/06/25/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"/>
    <id>www.strivezs.com/2020/06/25/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</id>
    <published>2020-06-25T09:10:22.814Z</published>
    <updated>2020-06-25T09:10:22.814Z</updated>
    
    <content type="html"><![CDATA[<h1 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h1><h2 id="贝叶斯决策"><a href="#贝叶斯决策" class="headerlink" title="贝叶斯决策"></a>贝叶斯决策</h2><p>首先来看贝叶斯分类, 贝叶斯公式如下：  </p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0F4bjdhSy5wbmc?x-oss-process=image/format,png" alt="figure.1"></p><p>其中 <strong>p(w) 为先验概率</strong>，表示每种类别分布的概率; <strong>p(x|w)为类条件概率</strong>, 表示在某种类别w的前提下, 某件事情x发生的概率; 而P(w|x) 为后验概率，表示某事x发生了，并且它属于某一类别w的概率，有了这个后验概率，我们就可以对样本进行分类。<strong>后验概率越大，说明某事物属于这个类别的可能性越大，我们越有理由把它x归到这个类别w下。</strong>  </p><p>这样我们就可以根绝p(w) p(x) p(x|w)来计算出p(w|x)从而得到x的类别划分.</p><h2 id="问题引出"><a href="#问题引出" class="headerlink" title="问题引出"></a>问题引出</h2><p>但是在实际问题中并不都是这样幸运的, 我们能获得的数据可能只有有限数目的样本数据，而++先验概率p(w)和类条件概率（各类的总体分布）p(x|w)都是未知的++.根据仅有的样本数据进行分类时，一种可行的办法是我们需要先对先验概率和类条件概率进行评估，然后在套用贝叶斯分类器。</p><p><strong>先验概率的估计较简单</strong>:1.每个样本所属的自然状态都是已知的（有点监督学习）2.依靠经验 3.用训练样本中各类出现的频率估计</p><p>类条件概率的估计很难，原因包括：1.概率密度函数包含了一个随机变量的全部信息；2.样本数据可能不多；3.特征向量x的维度可能很大等等<br>总之要直接估计类条件概率的密度函数很难。解决办法：<strong>把估计完全未知的概率密度 p(x|w)转换为估计参数。这样就将概率密度估计问题转化为了参数估计问题</strong> ==极大似然估计就是一种参数估计方法==。 当然，概率密度函数的选取很重要，模型正确，在样本区域无穷时，我们会得到较准的估计值，如果模型都错了，那估计半天的参数，肯定没有意义了。</p><h2 id="重要前提"><a href="#重要前提" class="headerlink" title="重要前提"></a>重要前提</h2><p><strong>训练样本的分布能代表样本的真实分布。每个样本集中的样本都是所谓++独立同分布额随机变量++，且有充分的训练样本。</strong></p><h2 id="极大似然估计-1"><a href="#极大似然估计-1" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>原理图：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0VrUTU5Yy5wbmc?x-oss-process=image/format,png" alt="figure.2"></p><p><strong>似然函数(likehood function)</strong> : 联合概率密度函数 $p(D|\theta)$ 称为相对于$\left\{ x_{1},x_{2},\dots ,x_{N} \right\}$ 的$\theta$的似然函数. 每个x都是独立的</p><script type="math/tex; mode=display">l(\theta)=p(D|\theta)=p(x_{1},x_{2},\dots,x_{N}|\theta)=\prod_{i=1}^{N}p(x_{i}|\theta)</script><p>如果 $\hat{\theta}$ 是参数空间中能使似然函数 $l(\theta)$ 最大的 $\theta$ 值，则$\hat{\theta}$应该是最可能的参数值，那么$\hat{\theta}$ 就是 $\theta$ 的极大似然估计量。它的样本集的函数记作：  </p><script type="math/tex; mode=display">\hat{\theta}=d(x_{1},x_{2},\dots,x_{N})=d(D)</script><script type="math/tex; mode=display">\hat{\theta}=d(x_{1},x_{2},\dots,x_{N}) $$ 称为极大似然函数估计值## 求解极大似然函数**ML估计**:求是的出现该组样本的概率最大的 $\theta$ 值。$$ \hat{\theta}=arg\: \underset{\theta}{max} \prod_{i=1}^{N}p(x_{i}|\theta)</script><p>实际中为了便于分析，定义了<strong>对数似然函数</strong>：</p><script type="math/tex; mode=display">H(\theta)=ln\:l(\theta)</script><script type="math/tex; mode=display">l(\theta)=p(D|\theta)=p(x_{1},x_{2},\dots,x_{N}|\theta)=\prod_{i=1}^{N}p(x_{i}|\theta)</script><script type="math/tex; mode=display">\hat{\theta}=arg\:H(\theta)=arg\: \underset{\theta}{max} \ln l(\theta)= arg\: \prod_{i=1}^{N}ln\:p(x_{i}|\theta)</script><p>1.未知参数只有一个（theta为标量）<br>在似然函数满足联系、可微的正则条件下，极大似然估计量是下面微分方程的解：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0FZSU1vaC5wbmc?x-oss-process=image/format,png" alt="figure.3"></p><p>2.未知参数有多个(theta为向量)<br>则theta可表示为具有S个分量的未知向量：</p><script type="math/tex; mode=display">\theta=[\theta_{1},\theta_{2},\dots,\theta_{s}]^{T}</script><p>记梯度算子：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyLzh6aVJkaC5wbmc?x-oss-process=image/format,png" alt="figure.4"></p><p>若似然函数满足连续可导的条件，则最大似然估计量就是如下方程的解.</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL2RQbG0xaS5wbmc?x-oss-process=image/format,png" alt="figure.5"></p><p>方程的解只是一个估计值，只有在样本数趋于无限多的时候，它才会接近于真实值，</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20venlwNTIxL3VwbG9hZF9pbWFnZS9yYXcvbWFzdGVyL0RvdTNHRC5wbmc?x-oss-process=image/format,png" alt="figure.6"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>求解最大似然估计量的一般步骤：</strong></p><ul><li>写出似然函数</li><li>写出对数似然函数，并整理</li><li>求对数似然函数关于标量/向量theta的导数，在上面例子中theta为向量=(u,sigma)</li><li>求解似然方程，将求导后的结果等于0 （满足dH(theta)/d theta=0</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;极大似然估计&quot;&gt;&lt;a href=&quot;#极大似然估计&quot; class=&quot;headerlink&quot; title=&quot;极大似然估计&quot;&gt;&lt;/a&gt;极大似然估计&lt;/h1&gt;&lt;h2 id=&quot;贝叶斯决策&quot;&gt;&lt;a href=&quot;#贝叶斯决策&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="Math" scheme="www.strivezs.com/categories/Math/"/>
    
    
      <category term="极大似然估计" scheme="www.strivezs.com/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch中nn.Linear()理解</title>
    <link href="www.strivezs.com/2020/06/21/PyTorch%E4%B8%ADnn.Linear()%E7%90%86%E8%A7%A3/"/>
    <id>www.strivezs.com/2020/06/21/PyTorch%E4%B8%ADnn.Linear()%E7%90%86%E8%A7%A3/</id>
    <published>2020-06-21T10:34:37.707Z</published>
    <updated>2020-06-21T10:34:37.707Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PyTorch中nn-Linear-理解"><a href="#PyTorch中nn-Linear-理解" class="headerlink" title="PyTorch中nn.Linear()理解"></a>PyTorch中nn.Linear()理解</h1><h2 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h2><script type="math/tex; mode=display">y = xA^{T}+b</script><p>这里A为weight，b为bias。</p><h2 id="代码部分"><a href="#代码部分" class="headerlink" title="代码部分"></a>代码部分</h2><h3 id="初始化部分代码"><a href="#初始化部分代码" class="headerlink" title="初始化部分代码"></a>初始化部分代码</h3><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="constructor">Linear(Module)</span>:</span><br><span class="line">...</span><br><span class="line">__constants__ = <span class="literal">['<span class="identifier">bias</span>']</span></span><br><span class="line"></span><br><span class="line">def <span class="constructor">__init__(<span class="params">self</span>, <span class="params">in_features</span>, <span class="params">out_features</span>, <span class="params">bias</span>=True)</span>:</span><br><span class="line">    super(Linear, self).<span class="constructor">__init__()</span></span><br><span class="line">    self.in_features = in_features</span><br><span class="line">    self.out_features = out_features</span><br><span class="line">    self.weight = <span class="constructor">Parameter(<span class="params">torch</span>.Tensor(<span class="params">out_features</span>, <span class="params">in_features</span>)</span>)</span><br><span class="line">    <span class="keyword">if</span> bias:</span><br><span class="line">        self.bias = <span class="constructor">Parameter(<span class="params">torch</span>.Tensor(<span class="params">out_features</span>)</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.register<span class="constructor">_parameter('<span class="params">bias</span>', None)</span></span><br><span class="line">    self.reset<span class="constructor">_parameters()</span></span><br></pre></td></tr></table></figure><h3 id="计算部分"><a href="#计算部分" class="headerlink" title="计算部分"></a>计算部分</h3><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@weak_script_method</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(<span class="keyword">self</span>, input)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> F.linear(input, <span class="keyword">self</span>.weight, <span class="keyword">self</span>.bias)</span><br></pre></td></tr></table></figure><p>返回值为: input * weight + bias</p><h3 id="bias和weight"><a href="#bias和weight" class="headerlink" title="bias和weight"></a>bias和weight</h3><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">weight</span>: the learnable weights of the module of shape</span><br><span class="line">    :<span class="attribute">math</span>:<span class="built_in">`(\text&#123;out\_features&#125;, \text&#123;in\_features&#125;)`</span>. The values are</span><br><span class="line">    initialized <span class="attribute">from </span>:<span class="attribute">math</span>:<span class="built_in">`\mathcal&#123;U&#125;(-\sqrt&#123;k&#125;, \sqrt&#123;k&#125;)`</span>, where</span><br><span class="line">    :<span class="attribute">math</span>:<span class="built_in">`k = \frac&#123;1&#125;&#123;\text&#123;in\_features&#125;&#125;`</span></span><br><span class="line"><span class="attribute">bias</span>:   the learnable bias of the module of <span class="attribute">shape </span>:<span class="attribute">math</span>:<span class="built_in">`(\text&#123;out\_features&#125;)`</span>.</span><br><span class="line">        <span class="attribute">If </span>:<span class="attribute">attr</span>:<span class="built_in">`bias`</span> is <span class="built_in">``</span>True<span class="built_in">``</span>, the values are initialized from</span><br><span class="line">        :<span class="attribute">math</span>:<span class="built_in">`\mathcal&#123;U&#125;(-\sqrt&#123;k&#125;, \sqrt&#123;k&#125;)`</span> where</span><br><span class="line">        :<span class="attribute">math</span>:<span class="built_in">`k = \frac&#123;1&#125;&#123;\text&#123;in\_features&#125;&#125;`</span></span><br></pre></td></tr></table></figure><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;</span>&gt; import torch</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; nn1 = torch.nn.Linear(<span class="number">100</span>, <span class="number">50</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; input1 = torch.randn(<span class="number">140</span>, <span class="number">100</span>)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; output1 = nn1(input1)</span><br><span class="line"><span class="meta">&gt;&gt;</span>&gt; output1.size()</span><br><span class="line">torch.Size([<span class="number">140</span>, <span class="number">50</span>])</span><br></pre></td></tr></table></figure><p>对于上述描述，我们创建一个input的维度为[140,100], 通过声明线性层会得到根据维度初始化的权重和偏差，其中weight的维度为[50,100]。对于公式中A表示的就是weight，而b表示的就是bias。由于对A进行了转置所以这里weight的维度为[50,100]而不是[100,50]。</p><p>具体计算为[140,100] × [50,100]的转置 + bias = [140,100] × [100,50] + bias最后得到的维度为[140,50]。</p><p>至于对于bias和weight的初始化，根绝网上所讲的是来有关维度值得均匀分布。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PyTorch中nn-Linear-理解&quot;&gt;&lt;a href=&quot;#PyTorch中nn-Linear-理解&quot; class=&quot;headerlink&quot; title=&quot;PyTorch中nn.Linear()理解&quot;&gt;&lt;/a&gt;PyTorch中nn.Linear()理解&lt;/h1
      
    
    </summary>
    
    
      <category term="PyTorch" scheme="www.strivezs.com/categories/PyTorch/"/>
    
      <category term="Python" scheme="www.strivezs.com/categories/PyTorch/Python/"/>
    
    
      <category term="Python" scheme="www.strivezs.com/tags/Python/"/>
    
      <category term="Pytorch" scheme="www.strivezs.com/tags/Pytorch/"/>
    
      <category term="Linear" scheme="www.strivezs.com/tags/Linear/"/>
    
  </entry>
  
  <entry>
    <title>Mac+PyCharm+Anaconda配置QtDesigner.md</title>
    <link href="www.strivezs.com/2020/06/17/Mac+PyCharm+Anaconda%E9%85%8D%E7%BD%AEQtDesigner.md/"/>
    <id>www.strivezs.com/2020/06/17/Mac+PyCharm+Anaconda%E9%85%8D%E7%BD%AEQtDesigner.md/</id>
    <published>2020-06-17T04:36:52.486Z</published>
    <updated>2020-06-17T04:36:52.486Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Mac-PyCharm-Anaconda配置QtDesigner"><a href="#Mac-PyCharm-Anaconda配置QtDesigner" class="headerlink" title="Mac+PyCharm+Anaconda配置QtDesigner"></a>Mac+PyCharm+Anaconda配置QtDesigner</h1><p>打开Pycharm-&gt;Perference-&gt;Tools-&gt;ExternalTools 添加下面两个外部工具。</p><h2 id="配置QtDesigner"><a href="#配置QtDesigner" class="headerlink" title="配置QtDesigner"></a>配置QtDesigner</h2><p>首先说明一下由于我这里是使用Anaconda进行配置的，因此我的路径可能和你默认使用的路径不同，下面我给出两种路径:<br><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">Anaconda:</span></span><br><span class="line">~opt<span class="meta-keyword">/anaconda3/</span>bin/Designer.app</span><br><span class="line"></span><br><span class="line">Mac默认路径：</span><br><span class="line"><span class="meta-keyword">/usr/</span>localCellar<span class="meta-keyword">/qt/</span><span class="number">5.10</span><span class="number">.1</span>/libexec</span><br></pre></td></tr></table></figure></p><p>下面是QtDesigner的配置信息，按照下图配置即可：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/H2IeEC.png" alt="figure.1"></p><h2 id="配置PyUIC"><a href="#配置PyUIC" class="headerlink" title="配置PyUIC"></a>配置PyUIC</h2><p>下面添加将.ui文件转换为.py文件的外部工具。</p><p>具体配置如下图：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/GQ8xLh.png" alt="figure.2"></p><ul><li>Program：选择python就可以了地址为：~/opt/anaconda3/bin/python3.7</li><li>Arguments：-m PyQt5.uic.pyuic $FileName$ -o $FileNameWithoutExtension$.py</li><li>Working directory：$ProjectFileDir$</li></ul><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>直接在Tools-&gt;Externel Tools中选择QtDesigner。  </p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/d0dsHg.png" alt="figure.3"></p><p>保存的文件一定要放在工作目录下，然后在选择PyUIC外部工具将ui选择为py文件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Mac-PyCharm-Anaconda配置QtDesigner&quot;&gt;&lt;a href=&quot;#Mac-PyCharm-Anaconda配置QtDesigner&quot; class=&quot;headerlink&quot; title=&quot;Mac+PyCharm+Anaconda配置QtDesi
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>微信公众号和CSDN的重新使用</title>
    <link href="www.strivezs.com/2020/06/05/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E5%92%8CCSDN%E7%9A%84%E9%87%8D%E6%96%B0%E4%BD%BF%E7%94%A8/"/>
    <id>www.strivezs.com/2020/06/05/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E5%92%8CCSDN%E7%9A%84%E9%87%8D%E6%96%B0%E4%BD%BF%E7%94%A8/</id>
    <published>2020-06-05T07:48:57.625Z</published>
    <updated>2020-06-05T07:48:57.625Z</updated>
    
    <content type="html"><![CDATA[<h1 id="微信公众号和CSDN的重新使用"><a href="#微信公众号和CSDN的重新使用" class="headerlink" title="微信公众号和CSDN的重新使用"></a>微信公众号和CSDN的重新使用</h1><p>最近计划将文章内容同步更新在个人博客、微信公众号和CSDN三个平台上，方便更多地用户进行访问和获取的内容。</p><h2 id="微信公众号"><a href="#微信公众号" class="headerlink" title="微信公众号"></a>微信公众号</h2><p>近期刚刚开通了微信公众号，过段时间会慢慢的进行更新的。</p><p>下面是公众号的二维码，可以扫描关注。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/公众号.jpg" alt="figure.1"></p><p>同样可以搜索次猿技术进行关注。</p><h2 id="CSDN"><a href="#CSDN" class="headerlink" title="CSDN"></a>CSDN</h2><p>CSDN之前曾经使用过一段时间，但是由于时间上的安排，决定仅在博客上进行更新了，现在正值毕业季时间比较充裕，因此决定再次重新进行更新。</p><p>欢迎访问：<a href="https://blog.csdn.net/qq_16184125">我的CSDN</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;微信公众号和CSDN的重新使用&quot;&gt;&lt;a href=&quot;#微信公众号和CSDN的重新使用&quot; class=&quot;headerlink&quot; title=&quot;微信公众号和CSDN的重新使用&quot;&gt;&lt;/a&gt;微信公众号和CSDN的重新使用&lt;/h1&gt;&lt;p&gt;最近计划将文章内容同步更新在个人博客
      
    
    </summary>
    
    
      <category term="技术" scheme="www.strivezs.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="CSDN" scheme="www.strivezs.com/tags/CSDN/"/>
    
      <category term="微信公众号" scheme="www.strivezs.com/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/"/>
    
  </entry>
  
  <entry>
    <title>百度AI studio+Encoder_Decoder+Anaconda+ V100+ Linux+PyTorch环境配置</title>
    <link href="www.strivezs.com/2020/05/22/%E7%99%BE%E5%BA%A6AI%20studio+Encoder_Decoder+Anaconda+%20V100+%20Linux+PyTorch%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>www.strivezs.com/2020/05/22/%E7%99%BE%E5%BA%A6AI%20studio+Encoder_Decoder+Anaconda+%20V100+%20Linux+PyTorch%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</id>
    <published>2020-05-22T09:46:03.172Z</published>
    <updated>2020-05-22T09:46:03.172Z</updated>
    
    <content type="html"><![CDATA[<h1 id="百度AI-studio-Encoder-Decoder-Anaconda-V100-Linux-PyTorch环境配置"><a href="#百度AI-studio-Encoder-Decoder-Anaconda-V100-Linux-PyTorch环境配置" class="headerlink" title="百度AI studio+Encoder_Decoder+Anaconda+ V100+ Linux+PyTorch环境配置"></a>百度AI studio+Encoder_Decoder+Anaconda+ V100+ Linux+PyTorch环境配置</h1><p>这里主要以我的毕设代码需要的环境进行配置的，该内容配合miniconda可以扩展到其他的环境下。</p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="dataset存储"><a href="#dataset存储" class="headerlink" title="dataset存储"></a>dataset存储</h3><p>由于在百度AI Studio中每次项目终止后，data数据集文件夹会按照数据集中的内容重置，因此我需要将需要的数据自行解压到work文件夹下，这样需要的内容就可以保存下载来了。具体解压代码：<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rar x abc.rar <span class="regexp">/home/</span>aistudio<span class="regexp">/work/</span>....<span class="regexp">/</span></span><br></pre></td></tr></table></figure></p><h3 id="Miniconda"><a href="#Miniconda" class="headerlink" title="Miniconda"></a>Miniconda</h3><p><strong>问题</strong>：由于我之前直接在linux下的python进行pytorch的安装，这种情况只能在项目未关闭的情况下使用，但是当我第二天重启之后发现自动重置了，我之前安装的没了，因此下面我重新装了一个miniconda进行包管理，这样在下次重启之后不会被重置了。</p><h4 id="安装miniconda及其配置"><a href="#安装miniconda及其配置" class="headerlink" title="安装miniconda及其配置"></a>安装miniconda及其配置</h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">下载：</span><br><span class="line">wget -<span class="keyword">c</span> http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/miniconda/Miniconda3-<span class="number">4.7</span>.<span class="number">12.1</span>-Linux-x86_64.<span class="keyword">sh</span></span><br><span class="line">安装：</span><br><span class="line">bash Miniconda3-<span class="number">4.7</span>.<span class="number">12.1</span>-Linux-x86_64.<span class="keyword">sh</span></span><br><span class="line"></span><br><span class="line">激活conda：</span><br><span class="line"><span class="keyword">source</span> ~/miniconda3/bin/avtivate</span><br><span class="line"></span><br><span class="line">更换清华源：</span><br><span class="line">conda config --<span class="built_in">add</span> channels http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/pkgs/free/ </span><br><span class="line">conda config --<span class="built_in">add</span> channels http<span class="variable">s:</span>//mirrors.tuna.tsinghua.edu.<span class="keyword">cn</span>/anaconda/pkgs/main/ </span><br><span class="line">conda config --<span class="keyword">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><p>完成上述操作后，重启一下终端</p><h4 id="配置PyTorch环境"><a href="#配置PyTorch环境" class="headerlink" title="配置PyTorch环境"></a>配置PyTorch环境</h4><p>创建conda新环境并且配置需要的包<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">激活conda</span><br><span class="line">source ~/miniconda3/bin/activate</span><br><span class="line"></span><br><span class="line">创建环境</span><br><span class="line">conda create --name Env_PyTorch <span class="attribute">python</span>=3.7</span><br><span class="line"></span><br><span class="line">进入创建好的环境</span><br><span class="line">conda activate Env_Pytoch</span><br><span class="line"></span><br><span class="line">安装PyTorch</span><br><span class="line">conda install <span class="attribute">pytorch</span>==1.2.0 <span class="attribute">torchvision</span>==0.4.0 <span class="attribute">cudatoolkit</span>=9.2</span><br><span class="line">(去除掉-c pytorch才是使用清华源进行安装的否则仍然是原有的源安装)</span><br><span class="line"></span><br><span class="line">配置其他的需要的包</span><br><span class="line">conda install ipython</span><br><span class="line">conda install scikit-image</span><br><span class="line">conda install <span class="attribute">scipy</span>==1.2.0</span><br><span class="line">conda install tqdm</span><br><span class="line">conda install <span class="attribute">pillow</span>=6.1</span><br><span class="line">conda install h5py</span><br><span class="line">conda install nltk</span><br></pre></td></tr></table></figure></p><h4 id="验证是否安装PyTorch成功"><a href="#验证是否安装PyTorch成功" class="headerlink" title="验证是否安装PyTorch成功"></a>验证是否安装PyTorch成功</h4><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line">&gt;&gt;&gt;import torch &gt;&gt;&gt;print(<span class="name">torch</span>.cuda.is_available()) </span><br><span class="line">&gt;&gt;&gt;print(<span class="name">torch</span>.__version__)</span><br></pre></td></tr></table></figure><p><strong>注意</strong>：每次重启终端都要重新运行<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">source</span> ~<span class="regexp">/work/mi</span>niconda3<span class="regexp">/bin/</span>activate </span><br><span class="line">conda activate Env_PyTorch</span><br></pre></td></tr></table></figure></p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p>我想把本地项目文件上传至Notebook项目中, 但文件数量比较多, 怎么上传? （详见官方帮助文档） </p><ul><li>请将项目文件打成zip包后, 在Notebook环境中上传. 如果项目文件较大(&gt;30mb), 请使用数据集功能上传, 然后挂载到项目中.</li><li>最后在项目中通过unzip命令进行解压缩(请注意需要解压到work目录下)<br>如：将压缩文件text.zip在指定目录/tmp下解压缩，如果已有相同的文件存在，要求unzip命令不覆盖原 先的文件。<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip -<span class="keyword">n</span> <span class="keyword">test</span>.<span class="keyword">zip</span> -<span class="keyword">d</span> /tmp</span><br></pre></td></tr></table></figure></li><li>如执意需要.rar包, 由于该格式为RAR共享软件独有<br>使用如下语句：<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rar 即可得到命令格式和所有参数</span><br><span class="line">rar x abc.rar <span class="regexp">/home/</span>aistudio<span class="regexp">/work/</span>....<span class="regexp">/</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;百度AI-studio-Encoder-Decoder-Anaconda-V100-Linux-PyTorch环境配置&quot;&gt;&lt;a href=&quot;#百度AI-studio-Encoder-Decoder-Anaconda-V100-Linux-PyTorch环境配置&quot; 
      
    
    </summary>
    
    
      <category term="Knowledge" scheme="www.strivezs.com/categories/Knowledge/"/>
    
      <category term="毕设" scheme="www.strivezs.com/categories/Knowledge/%E6%AF%95%E8%AE%BE/"/>
    
      <category term="Linux" scheme="www.strivezs.com/categories/Knowledge/%E6%AF%95%E8%AE%BE/Linux/"/>
    
    
      <category term="Anaconda" scheme="www.strivezs.com/tags/Anaconda/"/>
    
      <category term="Linux" scheme="www.strivezs.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>使用百度 AI Studio来跑深度学习</title>
    <link href="www.strivezs.com/2020/05/22/%E4%BD%BF%E7%94%A8%E7%99%BE%E5%BA%A6%20AI%20Studio%E6%9D%A5%E8%B7%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>www.strivezs.com/2020/05/22/%E4%BD%BF%E7%94%A8%E7%99%BE%E5%BA%A6%20AI%20Studio%E6%9D%A5%E8%B7%91%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-05-22T09:45:57.928Z</published>
    <updated>2020-05-22T09:45:57.928Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用百度-AI-Studio来跑深度学习"><a href="#使用百度-AI-Studio来跑深度学习" class="headerlink" title="使用百度 AI Studio来跑深度学习"></a>使用百度 AI Studio来跑深度学习</h1><p>ps：这里不仅限于跑深度学习，可运行python代码。</p><p>具体网站:<a href="https://aistudio.baidu.com/">click here</a></p><p><strong>这里做完四个任务可以得到100小时的计算时长，同样每天运行项目可以得到12小时的计算时长！太香了~</strong></p><h2 id="导入自己的项目"><a href="#导入自己的项目" class="headerlink" title="导入自己的项目"></a>导入自己的项目</h2><h3 id="创建数据集"><a href="#创建数据集" class="headerlink" title="创建数据集"></a>创建数据集</h3><p>创建数据集并上传数据集压缩包（这里可用用别人开源的数据集）</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Oc0r22.png" alt="figure.1"></p><h3 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h3><p>这里建议创建jupyter notebook的项目，因为他可以操控终端，这样就给了我们很多的可能，嘿嘿。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/2qCy98.png" alt="figure.2"></p><p>直接启动环境打开终端，如果有计算时长可能选择高性能的tesla v100计算卡哦。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/HWwpSU.png" alt="figure.3"></p><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>在终端中输入如下命令可以查看显卡配置<br><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">NVIDIA-smi</span></span><br></pre></td></tr></table></figure></p><p>如下：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/123.png" alt="figure.4"></p><p>在终端输入如下命令，可以查看cuda版本。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">nvcc -V</span></span><br></pre></td></tr></table></figure><p>查看cuda环境配置，然后去PyTorch官方找到对应的pytorch版本进行命令行安装即可。</p><p>这样运行神经网络的基础配置就设置好了，</p><h3 id="上传项目"><a href="#上传项目" class="headerlink" title="上传项目"></a>上传项目</h3><p>进入项目后，点击上传按钮，将需要的代码文件上传到服务器即可。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/UGMnEc.png" alt="figure.5"></p><h2 id="Final"><a href="#Final" class="headerlink" title="Final"></a>Final</h2><p>最后这里特别说明一下，服务器的系统环境是linux内核，所以基本上各种数据集的解压（压缩包形式数据集）文件创建删除，代码的运行都是使用命令行来完成的。</p><p>将压缩包abc.rar 解压到指定路径<br><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rar x abc.rar <span class="regexp">/home/</span>aistudio<span class="regexp">/work/</span>....<span class="regexp">/</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用百度-AI-Studio来跑深度学习&quot;&gt;&lt;a href=&quot;#使用百度-AI-Studio来跑深度学习&quot; class=&quot;headerlink&quot; title=&quot;使用百度 AI Studio来跑深度学习&quot;&gt;&lt;/a&gt;使用百度 AI Studio来跑深度学习&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="Neural Network" scheme="www.strivezs.com/categories/Neural-Network/"/>
    
      <category term="Artificial Intelligence" scheme="www.strivezs.com/categories/Neural-Network/Artificial-Intelligence/"/>
    
      <category term="Knowledge" scheme="www.strivezs.com/categories/Neural-Network/Artificial-Intelligence/Knowledge/"/>
    
    
      <category term="Neural Network" scheme="www.strivezs.com/tags/Neural-Network/"/>
    
      <category term="Server" scheme="www.strivezs.com/tags/Server/"/>
    
  </entry>
  
  <entry>
    <title>MAC+XAMPP+PHPStorm+XDebug</title>
    <link href="www.strivezs.com/2020/05/06/MAC+XAMPP+PHPStorm+XDebug/"/>
    <id>www.strivezs.com/2020/05/06/MAC+XAMPP+PHPStorm+XDebug/</id>
    <published>2020-05-06T03:13:22.764Z</published>
    <updated>2020-05-06T03:13:22.764Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MAC-XAMPP-PHPStorm-XDebug"><a href="#MAC-XAMPP-PHPStorm-XDebug" class="headerlink" title="MAC+XAMPP+PHPStorm+XDebug"></a>MAC+XAMPP+PHPStorm+XDebug</h1><p>在网上找了半天，花费了很长时间，总结了网上的内容，发现写的都不是十分全面，这里我写了从头到尾的配置过程。</p><h2 id="下载并安装XAMPP"><a href="#下载并安装XAMPP" class="headerlink" title="下载并安装XAMPP"></a>下载并安装XAMPP</h2><p>首先先去官网下载：<a href="https://www.apachefriends.org/zh_cn/index.html">click here</a>  </p><p>ps:个人补充一点，由于我上来先安装的是最新版本的导致我出现了许多问题，后来我尝试更换成了php7.3版本的XAMPP使用。</p><h2 id="下载并安装PHPStorm"><a href="#下载并安装PHPStorm" class="headerlink" title="下载并安装PHPStorm"></a>下载并安装PHPStorm</h2><p>直接去官网下载并且安装即可，注意如果你不是教育版或者企业版，则需要购买或者使用密钥（自行查找吧）。 <a href="https://www.jetbrains.com/phpstorm/">click here</a></p><h2 id="配置XAMPP"><a href="#配置XAMPP" class="headerlink" title="配置XAMPP"></a>配置XAMPP</h2><p>安装XMAPP之后，我们首先要配置一下conf文件.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/U8PIJ1.png" alt="figure.1"></p><p>添加上你的端口，这里phpstorm默认使用的63342端口，因此我在配置文件中添加上了63342端口。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/gEdJga.png" alt="figure.2"></p><p>修改成你想要的主站文件夹地址，由于它默认需要你将写好的文件放入到htdocs文件夹中，因此这里我为了方便自定义，我就修改了默认的主站地址。<strong>注意这里写的内容将会成为你的localhost映射的地址</strong>，在后面phpstorm项目配置的时候要注意，这里建议给一个比较大的文件范围作为默认的主站地址。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/URpdu4.png" alt="figure.3"></p><p>如果没有权限的话，则将User 改成你自己的用户名即可。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/IiOE3f.png" alt="figure.4"></p><p>按照上述过程配置好之后，重启以下apache就可以监听对应端口了。至于MySQL的我暂时没有到放在以后去写了。</p><h2 id="PHPStorm配置"><a href="#PHPStorm配置" class="headerlink" title="PHPStorm配置"></a>PHPStorm配置</h2><p>首先是创建一个PHP项目，然后打开Preferences-&gt;Debugger设置一下端口号，这里我们直接使用的默认63342的，如果你不使用默认的话，这里修改了对应着conf配置文件也要修改。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Ql0vJT.png" alt="figure.5"></p><p>然后打开Deployment设置部署事宜。  </p><p>创建一个local or mounted folder，然后设置一下项目地址，以及启动的网站，这里如果不是默认80端口的话，都要添加上自己端口号。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/POJUXS.png" alt="figure.6"></p><p>点开映射部分，设置一下自己的映射，<strong>注意这里之前在conf文件夹中设置了父级主站目录</strong>，因此我们需要在Web Path一栏中设置一下详细的目录，并且在local path中添加上项目地址。具体如下：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/4DEfk5.png" alt="figure.7"></p><p>配置完成之后一定要点一下那个小对勾，将该服务器设置为默认服务器。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/DdckXH.png" alt="figure.8"></p><h2 id="配置PHP"><a href="#配置PHP" class="headerlink" title="配置PHP"></a>配置PHP</h2><p>注意如果你是mac系统的话，则不需要使用xampp的php，可以直接使用你mac自导的php，在终端输入php-version可以查看当前php的版本，然后你打开Preferences-&gt;-&gt; Language -&gt; PHP 来选择你的解释器，默认是没有选择的。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/mNJ27O.png" alt="figure.9"></p><p>注意两个栏的版本要一直，如果想要使用xampp中的php，则新建一个php，然后找到XAMPP/xamppfiles/bin/php-7.3.17来创建一个新的php。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/SQdQUu.png" alt="figure.13"></p><h2 id="配置XDebug"><a href="#配置XDebug" class="headerlink" title="配置XDebug"></a>配置XDebug</h2><h3 id="安装xdebug扩展"><a href="#安装xdebug扩展" class="headerlink" title="安装xdebug扩展"></a>安装xdebug扩展</h3><ul><li>查询与当前环境匹配的 xdebug 版本 <a href="https://xdebug.org/wizard">click here</a></li><li>进入bin文件夹，cd /Applications/XAMPP/bin</li><li>sudo ./pecl search xdebug-2.x.x 这里的版本号根据上面查找到的</li><li>sudo ./pecl install xdebug-2.x.x  安装</li><li>在etc文件夹中找到php.ini的最后添加如下内容<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">zend_extension</span>=/Applications/XAMPP/xamppfiles/lib/php/extensions/<span class="literal">no</span>-debug-non-zts-<span class="number">20180731</span>/xdebug.so <span class="comment">;该行内容在安装完 xdebug 后，可从安装结束语中获取</span></span><br><span class="line"><span class="attr">xdebug.remote_enable</span> = <span class="number">1</span></span><br><span class="line"><span class="attr">xdebug.remote_host</span> = <span class="number">127.0</span>.<span class="number">0.1</span></span><br><span class="line"><span class="attr">xdebug.remote_port</span> = <span class="number">9000</span></span><br><span class="line"><span class="attr">xdebug.idekey</span> = PHPSTORM</span><br><span class="line"><span class="attr">xdebug.auto_start</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li>重启apache服务器</li></ul><h3 id="配置PHP-1"><a href="#配置PHP-1" class="headerlink" title="配置PHP"></a>配置PHP</h3><p>打开Perference-&gt;Language-&gt;Debuger, 设置端口号为9000</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/fz3haO.png" alt="figure.13"></p><p>打开Perference-&gt;Language-&gt;Debuger-&gt;DBGp Proxy 配置代理信息</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/dlnNw2.png" alt="figure.14"></p><p>配置Server</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/fFrJL9.png" alt="figure.15"></p><p>创建PHP Web并进行配置</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/4uL0fc.png" alt="figure.16"></p><h3 id="安装Chrome插件"><a href="#安装Chrome插件" class="headerlink" title="安装Chrome插件"></a>安装Chrome插件</h3><p>安装Chrome xdebug 插件，并且配置为debug模式 <a href="https://chrome.google.com/webstore/detail/xdebug-helper/eadndfjplgieldjbigjakmdgkmoaaaoc?utm_source=chrome-ntp-icon">click here</a></p><h3 id="PHPSTORM开启监听"><a href="#PHPSTORM开启监听" class="headerlink" title="PHPSTORM开启监听"></a>PHPSTORM开启监听</h3><p>绿色小电话！！！</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/t2AJ2X.png" alt="figure.17"></p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>当你配置完成之后，创建一个php文件。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>id<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="php"><span class="meta">&lt;?php</span></span></span><br><span class="line"><span class="php"> <span class="keyword">echo</span> <span class="string">"hello world"</span>;</span></span><br><span class="line"><span class="php"><span class="meta">?&gt;</span></span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>单击chrome运行即可以在浏览器中查看项目。</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/ENYizv.png" alt="figure.10"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/HSYcz5.png" alt="figure.11"></p><p>ps：补充一年，如果你想设置运行按钮单击直接显示网页的话，则添加一个PHP Web Page</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/yCmBS9.png" alt="figure.12"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MAC-XAMPP-PHPStorm-XDebug&quot;&gt;&lt;a href=&quot;#MAC-XAMPP-PHPStorm-XDebug&quot; class=&quot;headerlink&quot; title=&quot;MAC+XAMPP+PHPStorm+XDebug&quot;&gt;&lt;/a&gt;MAC+XAMPP+P
      
    
    </summary>
    
    
      <category term="文章页" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/"/>
    
      <category term="PHP" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/PHP/"/>
    
    
      <category term="PHP" scheme="www.strivezs.com/tags/PHP/"/>
    
      <category term="PHPStorm" scheme="www.strivezs.com/tags/PHPStorm/"/>
    
      <category term="XAMPP" scheme="www.strivezs.com/tags/XAMPP/"/>
    
      <category term="XDebug" scheme="www.strivezs.com/tags/XDebug/"/>
    
  </entry>
  
  <entry>
    <title>Anaconda配置清华源并且安装PyTorch.md</title>
    <link href="www.strivezs.com/2020/04/22/Anaconda%E9%85%8D%E7%BD%AE%E6%B8%85%E5%8D%8E%E6%BA%90%E5%B9%B6%E4%B8%94%E5%AE%89%E8%A3%85PyTorch.md/"/>
    <id>www.strivezs.com/2020/04/22/Anaconda%E9%85%8D%E7%BD%AE%E6%B8%85%E5%8D%8E%E6%BA%90%E5%B9%B6%E4%B8%94%E5%AE%89%E8%A3%85PyTorch.md/</id>
    <published>2020-04-22T03:36:21.885Z</published>
    <updated>2020-04-22T03:36:21.885Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Anaconda配置清华源并且安装PyTorch"><a href="#Anaconda配置清华源并且安装PyTorch" class="headerlink" title="Anaconda配置清华源并且安装PyTorch"></a>Anaconda配置清华源并且安装PyTorch</h1><h2 id="配置清华源"><a href="#配置清华源" class="headerlink" title="配置清华源"></a>配置清华源</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">配置基础包：</span><br><span class="line">conda config --add channels http:<span class="regexp">//mi</span>rror.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>pkgs<span class="regexp">/main/</span></span><br><span class="line">conda config --add channels http:<span class="regexp">//mi</span>rror.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>pkgs<span class="regexp">/free/</span></span><br><span class="line"></span><br><span class="line">配置拓展包比如PyTorch</span><br><span class="line">conda config --add channels https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>cloud<span class="regexp">/conda-forge/</span> </span><br><span class="line">conda config --add channels https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>cloud<span class="regexp">/msys2/</span> </span><br><span class="line">conda config --add channels https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>cloud<span class="regexp">/bioconda/</span> </span><br><span class="line">conda config --add channels https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>cloud<span class="regexp">/menpo/</span> </span><br><span class="line">conda config --add channels https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/anaconda/</span>cloud<span class="regexp">/pytorch/</span></span><br><span class="line"></span><br><span class="line">执行：</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><h2 id="安装PyTorch"><a href="#安装PyTorch" class="headerlink" title="安装PyTorch"></a>安装PyTorch</h2><p>去官网选择对应的版本安装，<strong>需要注意的是要去掉 -c pytorch 否则安装的源来自于官网而不是自己之前设置的源</strong></p><p>如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision <span class="attribute">cudatoolkit</span>=9.0 -c pytorch</span><br><span class="line">改为</span><br><span class="line">conda install pytorch torchvision <span class="attribute">cudatoolkit</span>=9.0</span><br></pre></td></tr></table></figure><p>建议：在我们搭建好环境之后，最好就先添加镜像站到Anaconda中，这样安装包的时候，速度会得到大大的提升</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Anaconda配置清华源并且安装PyTorch&quot;&gt;&lt;a href=&quot;#Anaconda配置清华源并且安装PyTorch&quot; class=&quot;headerlink&quot; title=&quot;Anaconda配置清华源并且安装PyTorch&quot;&gt;&lt;/a&gt;Anaconda配置清华源并
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Word Embedding</title>
    <link href="www.strivezs.com/2020/04/04/Word%20Embedding/"/>
    <id>www.strivezs.com/2020/04/04/Word%20Embedding/</id>
    <published>2020-04-04T09:54:30.990Z</published>
    <updated>2020-04-04T09:54:30.990Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="引入One-Hot"><a href="#引入One-Hot" class="headerlink" title="引入One-Hot"></a>引入One-Hot</h3><p>自然语言处理主要研究语言信息，语言（词、句子等）属于人类认知过程中产生的高层认知抽象实体，而语言和图像属于较低层的元时输入信号。语音、图像和数据表达不需要特殊的编码，并且有天生的顺序性和关联性，近似的数字会被认为是近似的特征集合。正如图像是由像素的组成，语言是由词或字组成，可以把语言转换为词或字表示的结合。<br>然后，不同于像素的大小天生具有色彩信息，词的数值大小很难表征词的含义。最后，人们为了方便，<strong>采用One-Hot编码格式</strong>，以一个只有10个不同词的语料库为例，我们可以用一个10位的向量来表示每个词，该向量在词下标位置的值为1，而其他全部为0.</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">第一个词：[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">第二个词: [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">·····</span><br><span class="line">第十个词：[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>这种词的表示方法十分简单，也很容易实现，充分解决了分类器难以处理属性数据的问题。但是它的<strong>缺点</strong>也很明显：冗余太多、无法体现词与词之间的关系。可以看到，这10个词的表示，彼此之间都是相互正交的。同时，随着词数的，One-Hot向量的维度也会急剧增长，如果有3000个不同的词，那么每个One-Hot词向量都是3k维，而且只有一个位置为1，其余位置都是0。（<strong>这里感觉为了节省的可以采用（300，3000）来表示长度为3k的向量第300个位置上为1，其余都为0</strong>）。虽然One-Hot编码格式在传统任务上表现出色，但是由于词的维度太高了，应用在深度学习上时，常常出现维度灾难，++所以在深度学习中一般采用词向量的表示形式++。</p><h3 id="引入词向量"><a href="#引入词向量" class="headerlink" title="引入词向量"></a>引入词向量</h3><p>词向量(Word Vector)，也称为词嵌入(Word Embedding),并没有严格统一的定义。从概念上讲，<strong>它是指把一个维数为所有词的数量的高维空间(几万几十万个字)嵌入一个维数低得多的连续向量空间(128或256维)中，每个单词或词组被映射为实数域上的向量</strong>。<br>词向量有专门的训练方法，这里不会细讲，感兴趣的可以学习斯坦福的CS224系列课程。这里只需要了解<strong>词向量最重要的特征是相似词的词向量距离相近。每个词的词向量维度都是固定的，每一维都是连续的数。</strong></p><p>举个例子，如果我们用二维的词向量表示十个词：足球、比赛、教练、队伍、裤子、长裤、上衣和编制、折叠、拉，那么可视化出来的结果如下所示:</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/YorrIg.png" alt="figure.1"></p><p>可以看出，<strong>同类词彼此聚集，相互之间的距离较近</strong>。</p><p>由此可见，用词向量表示词，不仅所有维度会变少（十维变为二维），其中也会包含更合理的语义信息。除了相邻词距离更近之外，词向量还有不少有趣的特征，如下图所示：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/AlftfF.png" alt="figure.2"></p><p>虚线的的两端分别是男性词和女性词，例如：叔叔和阿姨、兄弟和姐妹、先生和女士。可以看出，虚线的方向和长度都差不多，因此可以认为：国王-女王≈男人-女人，即国王可以看成男性君主，女王可以看出女性君主，国王减去男性，只剩下君主的特征，女王减去女性，也只剩下君主的特征，所以这二者近似。</p><h2 id="具体介绍"><a href="#具体介绍" class="headerlink" title="具体介绍"></a>具体介绍</h2><p>英文一般是用一个向量表示一个单词，也有使用一个向量表示一个字母的情况。中文同样也有一个词或者一个字的词向量表示，与英文采用空格来区分词不同，中文的词与词之间没有间隔，因此<em>*如果采用基于词的词向量表示，需要先进行中文分词</em>。</p><p>这里只对词向量做一个概要性的介绍，让我们有一个直观地认知。我们只需要掌握词向量技术用向量表证词，相似词之间的向量距离近，</p><h3 id="PyTorch使用"><a href="#PyTorch使用" class="headerlink" title="PyTorch使用"></a>PyTorch使用</h3><p>在PyTorch中，针对词向量有一个专门的层<strong>nn.Embedding</strong>，++用来实现词与词向量的映射++。nn.Embedding具有一个权重，形状是(num_words,embedding_dim)，例如：对上述句子中的10个词，每个词用2维向量表征，对应的权重就是一个10×2的矩阵。<strong>Embedding的输入形状是N×W，N是batch size， W是序列长度，输出的形状是N×W×embedding_dim.输入必须是LongTensor，FloatTensor须通过tensor.long（）方法转成LongTensor</strong>。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># coding:utf8</span><br><span class="line"><span class="keyword">import</span> torch as t</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line">embedding = t.nn.Embedding(<span class="number">10</span>,<span class="number">2</span>) # 十个词，每个词用二维词向量表示</span><br><span class="line">input = t.arrange(<span class="number">0</span>,<span class="number">6</span>).view(<span class="number">3</span>,<span class="number">2</span>).long() # 三个句子，每个句子有两个词 N为<span class="number">3</span> W为<span class="number">2</span></span><br><span class="line">input = t.<span class="built_in">auto</span>grad.Variable(input)</span><br><span class="line">output = embedding(input)</span><br><span class="line">print(output.size())</span><br><span class="line">print(embedding.weight.size())</span><br></pre></td></tr></table></figure><p>输出:<br><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">3</span>L,<span class="number">2</span>L,<span class="number">2</span>L)</span><br><span class="line">(<span class="number">10</span>L,<span class="number">2</span>L)</span><br></pre></td></tr></table></figure></p><p>需要注意的是，Embedding的权重也是可以训练的，既可以采用随机初始化，也可以采用预训练好的词向量初始化。</p><h2 id="简单总结"><a href="#简单总结" class="headerlink" title="简单总结"></a>简单总结</h2><p>可以使用torch.nn.Embedding(num_words,embedding_dim)来生成一个大小为num_words×embedding_dim词向量，<br>其中共有num_words个单词，每个单词用一个二维词向量表示 类似横纵坐标 </p><p>输入到embedding中的tensor必须是LongTensor，如果是FloatTensor必须用long（）转换<br>Embedding的输入为N×W N是batch_size W是每个batch的单词数 如输入三个句子 每个句子包含两个单词<br>Embedding的输出为N×W×embedding 即为输出还是三个句子 每个句子仍然是两个单词表示 但是每个单词则用一个二维向量表示</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Word-Embedding&quot;&gt;&lt;a href=&quot;#Word-Embedding&quot; class=&quot;headerlink&quot; title=&quot;Word Embedding&quot;&gt;&lt;/a&gt;Word Embedding&lt;/h1&gt;&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a 
      
    
    </summary>
    
    
      <category term="Knowledge" scheme="www.strivezs.com/categories/Knowledge/"/>
    
      <category term="Nerual Network" scheme="www.strivezs.com/categories/Knowledge/Nerual-Network/"/>
    
    
      <category term="word embedding" scheme="www.strivezs.com/tags/word-embedding/"/>
    
  </entry>
  
  <entry>
    <title>环境配置：NVIDIA+Anaconda+PyTorch+PyCharm</title>
    <link href="www.strivezs.com/2020/03/18/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%EF%BC%9ANVIDIA+Anaconda+PyTorch+PyCharm/"/>
    <id>www.strivezs.com/2020/03/18/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%EF%BC%9ANVIDIA+Anaconda+PyTorch+PyCharm/</id>
    <published>2020-03-18T02:22:12.072Z</published>
    <updated>2020-03-18T02:22:12.072Z</updated>
    
    <content type="html"><![CDATA[<h1 id="环境配置：NVIDIA-Anaconda-PyTorch-PyCharm"><a href="#环境配置：NVIDIA-Anaconda-PyTorch-PyCharm" class="headerlink" title="环境配置：NVIDIA+Anaconda+PyTorch+PyCharm"></a>环境配置：NVIDIA+Anaconda+PyTorch+PyCharm</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="配置英伟达显卡"><a href="#配置英伟达显卡" class="headerlink" title="配置英伟达显卡"></a>配置英伟达显卡</h3><h4 id="安装CUDA"><a href="#安装CUDA" class="headerlink" title="安装CUDA"></a>安装CUDA</h4><ul><li>首先打开自己的英伟达控制面板查看自己的系统信息，如下图所示：我的是CUDA10.2.95因此需要去英伟达官网下载对应版本的CUDA，下载地址：<a href="https://developer.nvidia.com/cuda-downloads?target_os=Windows&amp;target_arch=x86_64&amp;target_version=10&amp;target_type=exenetwork">click here</a></li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/rr74XI.png" alt="figure.3"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/r1wfSH.png" alt="figure.0"></p><ul><li>进行安装，基本上就是傻瓜式下一步没什么，等待安装完成即可</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/QNrK0e.png" alt="figure.1"></p><h4 id="安装Cudnn"><a href="#安装Cudnn" class="headerlink" title="安装Cudnn"></a>安装Cudnn</h4><ul><li>首先去英伟达官网下载cudnn(这里需要登录下载)。具体下载链接：<a href="https://developer.nvidia.com/cudnn">click here</a></li><li>下载完成之后解压得到一个文件夹(蜜汁感动竟然是压缩包不用安装), 将文件夹中的内容放到在C盘路径为<strong>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.2\</strong>的对应文件夹中，直接复制进去就好了</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/PRdOlQ.png" alt="figure.2"></p><h3 id="配置PyTorch"><a href="#配置PyTorch" class="headerlink" title="配置PyTorch"></a>配置PyTorch</h3><ul><li>这里我使用的是anaconda来进行包的管理，具体anaconda下载地址： <a href="https://www.anaconda.com/">click here</a></li><li>PyTorch安装，<strong>切记这里需要安装和cuda对应版本的PyTorch！</strong></li><li>首先去PyTorch官网找到安装命令，如下图：</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/AxTd0k.png" alt="figure.4"></p><ul><li>然后在Anaconda中输入该命令即可：</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/PnvbJp.png" alt="figure.5"></p><ul><li>安装完成</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/dUyIVX.png" alt="figure.6"></p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><h3 id="版本验证"><a href="#版本验证" class="headerlink" title="版本验证"></a>版本验证</h3><ul><li>在命令行中输入<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">nvcc -V</span></span><br></pre></td></tr></table></figure>会观察到如下版本信息：</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/4ARnMy.png" alt="figure.7"></p><h3 id="PyCharm验证能够使用CUDA"><a href="#PyCharm验证能够使用CUDA" class="headerlink" title="PyCharm验证能够使用CUDA"></a>PyCharm验证能够使用CUDA</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(torch.__version__)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(torch.version.cuda)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(torch.cuda.is_available()</span></span>)</span><br></pre></td></tr></table></figure><p>如果输出结果为True，则表示cuda可以使用了。（建议不用最新版的NVIDIA驱动，否则CUDA版本也会升级 PyTorch不一定会有对应版本 没有对应版本不能正常使用。）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;环境配置：NVIDIA-Anaconda-PyTorch-PyCharm&quot;&gt;&lt;a href=&quot;#环境配置：NVIDIA-Anaconda-PyTorch-PyCharm&quot; class=&quot;headerlink&quot; title=&quot;环境配置：NVIDIA+Anaconda
      
    
    </summary>
    
    
      <category term="Knowledge" scheme="www.strivezs.com/categories/Knowledge/"/>
    
      <category term="PyTorch" scheme="www.strivezs.com/categories/Knowledge/PyTorch/"/>
    
    
      <category term="PyCharm" scheme="www.strivezs.com/tags/PyCharm/"/>
    
      <category term="NVIDIA" scheme="www.strivezs.com/tags/NVIDIA/"/>
    
      <category term="PyTorch" scheme="www.strivezs.com/tags/PyTorch/"/>
    
      <category term="CUDA" scheme="www.strivezs.com/tags/CUDA/"/>
    
  </entry>
  
  <entry>
    <title>使用CDN加速github page访问</title>
    <link href="www.strivezs.com/2020/02/22/%E4%BD%BF%E7%94%A8CDN%E5%8A%A0%E9%80%9Fgithub%20page%E8%AE%BF%E9%97%AE/"/>
    <id>www.strivezs.com/2020/02/22/%E4%BD%BF%E7%94%A8CDN%E5%8A%A0%E9%80%9Fgithub%20page%E8%AE%BF%E9%97%AE/</id>
    <published>2020-02-22T03:15:36.268Z</published>
    <updated>2020-02-22T03:15:36.268Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用CDN加速github-page访问"><a href="#使用CDN加速github-page访问" class="headerlink" title="使用CDN加速github page访问"></a>使用CDN加速github page访问</h1><p>这里我使用的<a href="https://portal.qiniu.com/">七牛云</a>来加速网站的访问.</p><p><strong>特别注意：你的域名一定要备案了才能用CDN！！！</strong></p><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="创建CDN域名加速实例"><a href="#创建CDN域名加速实例" class="headerlink" title="创建CDN域名加速实例"></a>创建CDN域名加速实例</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/099ePA.png" alt="figure1"></p><h3 id="配置实例"><a href="#配置实例" class="headerlink" title="配置实例"></a>配置实例</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/MNex84.png" alt="figure2"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/m4lIay.png" alt="figure3"></p><p>配置完如上实例后，需要等待实例状态变为成功:</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/XbWs3j.png" alt="figure4"></p><h3 id="添加到CNAME解析"><a href="#添加到CNAME解析" class="headerlink" title="添加到CNAME解析"></a>添加到CNAME解析</h3><p>打开你自己的域名管理控制台。这里我用的是阿里云的域名管理控制台，进行域名就解析的配置：</p><h4 id="配置www"><a href="#配置www" class="headerlink" title="配置www"></a>配置www</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/LnLHLc.png" alt="figure5"></p><h4 id="配置"><a href="#配置" class="headerlink" title="配置@"></a>配置@</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/opB6nc.png" alt="figure6"></p><h2 id="验证解析成功没有"><a href="#验证解析成功没有" class="headerlink" title="验证解析成功没有"></a>验证解析成功没有</h2><h3 id="mac-linux"><a href="#mac-linux" class="headerlink" title="mac/linux"></a>mac/linux</h3><p>在命令台输入<br><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">dig </span>你的网址</span><br></pre></td></tr></table></figure></p><p>如果返回如下结果则表明解释成功了.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/eI5g8q.png" alt="figure7"></p><h3 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h3><p>由于这里我是mac系统所以windows我就贴出网上找到的验证方式：</p><p>windows系统可以通过Win+R 或 点击左下角的“开始”按钮打开“开始”菜单，打开“运行”，输入cmd回车。</p><p>在命令行模式下输入nslookup 您的加速域名，例如 nslookup qn.vinchi.club,在结果中可以看到您复制的cname值即可</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Uz6PkK.jpg" alt="figure8"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用CDN加速github-page访问&quot;&gt;&lt;a href=&quot;#使用CDN加速github-page访问&quot; class=&quot;headerlink&quot; title=&quot;使用CDN加速github page访问&quot;&gt;&lt;/a&gt;使用CDN加速github page访问&lt;/h1&gt;&lt;
      
    
    </summary>
    
    
      <category term="文章页" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/"/>
    
      <category term="Github" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Github/"/>
    
      <category term="域名" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Github/%E5%9F%9F%E5%90%8D/"/>
    
    
      <category term="域名解析" scheme="www.strivezs.com/tags/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"/>
    
      <category term="Github Page" scheme="www.strivezs.com/tags/Github-Page/"/>
    
      <category term="CDN加速" scheme="www.strivezs.com/tags/CDN%E5%8A%A0%E9%80%9F/"/>
    
  </entry>
  
  <entry>
    <title>Learning In RNN Part II</title>
    <link href="www.strivezs.com/2020/02/16/Learning%20In%20RNN%20Part%20II/"/>
    <id>www.strivezs.com/2020/02/16/Learning%20In%20RNN%20Part%20II/</id>
    <published>2020-02-16T04:04:20.591Z</published>
    <updated>2020-02-16T04:04:20.591Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learning-In-RNN-Part-II"><a href="#Learning-In-RNN-Part-II" class="headerlink" title="Learning In RNN Part II"></a>Learning In RNN Part II</h1><p><strong>Learning Tager:</strong> Make the loss be minimize that evaluating by cost function.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/kHcMXX.png" alt="figure1"></p><h2 id="Unfortunately"><a href="#Unfortunately" class="headerlink" title="Unfortunately"></a>Unfortunately</h2><ul><li>RNN-based network is not always easy to learn.</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/8bJy2V.png" alt="figure2"></p><ul><li>Th error surface is rought</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/dy4doG.png" alt="figure3"></p><h2 id="Helpful-Techniques"><a href="#Helpful-Techniques" class="headerlink" title="Helpful Techniques"></a>Helpful Techniques</h2><h3 id="Long-Short-term-Memory-LSTM"><a href="#Long-Short-term-Memory-LSTM" class="headerlink" title="Long Short-term Memory(LSTM)"></a>Long Short-term Memory(LSTM)</h3><h4 id="Why-replace-RNN-to-LSTM"><a href="#Why-replace-RNN-to-LSTM" class="headerlink" title="Why replace RNN to LSTM?"></a>Why replace RNN to LSTM?</h4><p>Can deal with gradient vanishing(消灭，等于0) (not gradient explode爆炸激增)<br>It can make your error surface to be flatting nor not steep.<br>The specify performance is that it can remove the flat regions and solve the problem of gradient vanishing, but not gradient explode.  </p><h4 id="How-to-work"><a href="#How-to-work" class="headerlink" title="How to work:"></a>How to work:</h4><p>The different operation between RNN and LSTM is that RNN can reomve value in memory after each computation and store new value. But LSTM can add the previous value to new value in cell memory after each computation.(Concretely depend on the value of forget gate)<br>So the difference of RNN and LSTM is if a weight influence value of memory, the influence never disappears unless forget gate is closed.<br>If forget gate is opened, there no gradient vanishing.  </p><h4 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h4><ul><li>can deal with gradient vanishing(not gradient explode)</li><li>Memory and input are ++added++</li><li>The influence never disappears<br>unless forget gate is closed</li><li>No Gradient vanishing(If forget gate is opened)</li></ul><p>Gated Recurrent Unit(GRU):simpier thant LSTM</p><p><strong>Other helpful techniques:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/EDrdli.png" alt="figure4">  </p><h2 id="More-Applications"><a href="#More-Applications" class="headerlink" title="More Applications"></a>More Applications</h2><h3 id="Many-to-one"><a href="#Many-to-one" class="headerlink" title="Many to one"></a>Many to one</h3><ul><li>Input is a vector sequence, but output is only one vector.</li></ul><p><strong>Sentiment Analysis:(意见分析)</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/K5bxC0.png" alt="figure5"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/XKwMQM.png" alt="figure6"></p><h3 id="Many-to-Many-Output-is-shorter"><a href="#Many-to-Many-Output-is-shorter" class="headerlink" title="Many to Many (Output is shorter)"></a>Many to Many (Output is shorter)</h3><ul><li>Both input and output are both sequences, <strong>but the output is shorter</strong>.</li></ul><p><strong>Speech Recognition:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/QuBJ2j.png" alt="figure7"></p><h4 id="How-to-differentiate"><a href="#How-to-differentiate" class="headerlink" title="How to differentiate?"></a>How to differentiate?</h4><ul><li>Connectionist Temporal Classification(<strong>CTC</strong>，联结主义时间分类)</li></ul><p>==Add an extra symbol “Φ” representing “null”.==  </p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/kCJIsg.png" alt="figure8"></p><p>Use this method to slove the problem like differentiate “好棒” or “好棒棒”.  </p><h4 id="CTC-Training"><a href="#CTC-Training" class="headerlink" title="CTC Training"></a>CTC Training</h4><p><strong>Acoustic Features:(声音特征)</strong><br>ALL possible alignments(序列/顺序) are considered as correct because we don’t know what alignment is correct. So we can list all alignments to train.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/WPPHRn.png" alt="figure9"></p><h4 id="CTC-example"><a href="#CTC-example" class="headerlink" title="CTC: example"></a>CTC: example</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/3yexBF.png" alt="figure10"></p><h3 id="Many-to-Many-No-Limitation"><a href="#Many-to-Many-No-Limitation" class="headerlink" title="Many to Many (No Limitation)"></a>Many to Many (No Limitation)</h3><ul><li>Both input and output are both sequences <strong>with differnet lengths</strong>. ➡ <strong>Sequence to sequence learning</strong><br><strong>Machine Translate</strong>(Machine Learning ➡ 机器学习)</li></ul><p><strong>bag-of-word:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/HjyAMK.png" alt="figure11"></p><p>Above model can’t stop until it’s interrupted.</p><h4 id="How-to-make-the-network-stop"><a href="#How-to-make-the-network-stop" class="headerlink" title="How to make the network stop"></a>How to make the network stop</h4><ul><li>Adda a symbol ‘===’(断)</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/8Gu1j2.png" alt="figure12"></p><h3 id="Beyond-Sequence"><a href="#Beyond-Sequence" class="headerlink" title="Beyond Sequence"></a>Beyond Sequence</h3><ul><li>Syntactic parsing(句法分析)</li></ul><h4 id="Transform-Tree-Structure-to-sequence"><a href="#Transform-Tree-Structure-to-sequence" class="headerlink" title="Transform Tree Structure to sequence"></a>Transform Tree Structure to sequence</h4><p><strong>Conversion principle:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/BRp1UF.png" alt="figure13"></p><p>We can transform sentence tree to sequence by using this principle and train a sequence model to recognize sentence.  </p><h3 id="Sequence-to-sequence"><a href="#Sequence-to-sequence" class="headerlink" title="Sequence-to-sequence"></a>Sequence-to-sequence</h3><h4 id="Auto-encoder-Text"><a href="#Auto-encoder-Text" class="headerlink" title="Auto-encoder-Text"></a>Auto-encoder-Text</h4><ul><li>To understand the meaning of a word sequence, the order of the words can not be ignored.</li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/By7XBu.png" alt="figure14"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/wYKkpA.png" alt="figure15"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/eCiGf3.png" alt="figure16"></p><h4 id="Auto-encoder-Speech"><a href="#Auto-encoder-Speech" class="headerlink" title="Auto-encoder-Speech"></a>Auto-encoder-Speech</h4><ul><li>Dimension reduction for a sequence with variable length</li></ul><p>audio segments()word-level-&gt;Fixed-length vector  </p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/RARIzh.png" alt="figure17"></p><h5 id="Audio-Search-Principle"><a href="#Audio-Search-Principle" class="headerlink" title="Audio Search Principle:"></a><strong>Audio Search Principle:</strong></h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/zYlxJy.png" alt="figure18"></p><h5 id="How-to-transform-audio-segment-to-vector"><a href="#How-to-transform-audio-segment-to-vector" class="headerlink" title="How to transform audio segment to vector"></a>How to transform audio segment to vector</h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/tTKbLU.png" alt="figure19"></p><p>ps: jointly 共同地 同时地 similarity 相似 类似 embedding 埋入/埋葬  </p><h5 id="Visualizing-embedding-vectors-of-the-words"><a href="#Visualizing-embedding-vectors-of-the-words" class="headerlink" title="Visualizing embedding vectors of the words"></a>Visualizing embedding vectors of the words</h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/CGfD3r.png" alt="figure20"></p><h4 id="Sequence-to-sequence-Learning-Demo-Chat-bot"><a href="#Sequence-to-sequence-Learning-Demo-Chat-bot" class="headerlink" title="Sequence-to-sequence Learning Demo:Chat-bot"></a>Sequence-to-sequence Learning Demo:Chat-bot</h4><p><strong>Learning Principle:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/0szRES.png" alt="figure21"></p><p><strong>Data Set:</strong><br>40000 sentences in Movie album and discussion of presidential election in American.  </p><h2 id="Attention-based-Model"><a href="#Attention-based-Model" class="headerlink" title="Attention-based Model"></a>Attention-based Model</h2><p><strong>Structure Version 1:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Ajbf8o.png" alt="figure22"></p><p><strong>Structure Version 2:</strong><br>==Neural Turing Machine(神经图灵机)==</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/h4FdpY.png" alt="figure23"></p><h3 id="Reading-Comprehension"><a href="#Reading-Comprehension" class="headerlink" title="Reading Comprehension"></a>Reading Comprehension</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/ErGx83.png" alt="figure24"></p><h3 id="Visual-Question-Answering"><a href="#Visual-Question-Answering" class="headerlink" title="Visual Question Answering"></a>Visual Question Answering</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/opnM0d.png" alt="figure25"></p><p><strong>Principle:</strong><br>==A vector for each region==</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/QyhNhJ.png" alt="figure26"></p><h3 id="Speech-Question-Answering"><a href="#Speech-Question-Answering" class="headerlink" title="Speech Question Answering"></a>Speech Question Answering</h3><ul><li>TOEFL Listening Comprehension Test By Machine</li></ul><p><strong>Example:</strong>  </p><ol><li>Audio Story: the original story is 5 min long</li><li>Question: “what is possible of Venus’ clouds?”</li><li>Choices:<ol><li>gased released as a result of volcanic activity</li><li>chemical reactions caused by high surface temperatures</li><li>bursts of radio energy from the plane’s surface</li><li>strong winds that blow dust into the atmosphere</li></ol></li></ol><h4 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h4><p>Everything is learned from training examples.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/ADclLS.png" alt="figure27"></p><h2 id="Deep-amp-Structure"><a href="#Deep-amp-Structure" class="headerlink" title="Deep &amp; Structure"></a>Deep &amp; Structure</h2><h3 id="Integrated-together"><a href="#Integrated-together" class="headerlink" title="Integrated together"></a>Integrated together</h3><ul><li>Speech Recognition: CNN/LSTM/DNN+HMM<br><img src="https://gitee.com/zyp521/upload_image/raw/master/JKDhvu.jpg" alt="figure28"></li></ul><p>Bayes theorem</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/ssXaWg.png" alt="figure29"></p><ul><li>Sematic Tagging: Bi-directional LSTM+CRF/Structured SVM<br>Testing:<br><img src="https://gitee.com/zyp521/upload_image/raw/master/zryrFy.jpg" alt="figure31"></li></ul><p><img src="https://gitee.com/zyp521/upload_image/raw/master/GJhyYd.png" alt="figure30"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Learning-In-RNN-Part-II&quot;&gt;&lt;a href=&quot;#Learning-In-RNN-Part-II&quot; class=&quot;headerlink&quot; title=&quot;Learning In RNN Part II&quot;&gt;&lt;/a&gt;Learning In RNN P
      
    
    </summary>
    
    
      <category term="文章页" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/"/>
    
      <category term="Python" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/"/>
    
      <category term="Machine Learning" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/Machine-Learning/"/>
    
      <category term="Neural NetWork" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/Machine-Learning/Neural-NetWork/"/>
    
    
      <category term="Python" scheme="www.strivezs.com/tags/Python/"/>
    
      <category term="Machine Learning" scheme="www.strivezs.com/tags/Machine-Learning/"/>
    
      <category term="RNN" scheme="www.strivezs.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>将域名从服务器解析到github page上</title>
    <link href="www.strivezs.com/2020/02/16/%E5%B0%86%E5%9F%9F%E5%90%8D%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A7%A3%E6%9E%90%E5%88%B0github%20page%E4%B8%8A/"/>
    <id>www.strivezs.com/2020/02/16/%E5%B0%86%E5%9F%9F%E5%90%8D%E4%BB%8E%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A7%A3%E6%9E%90%E5%88%B0github%20page%E4%B8%8A/</id>
    <published>2020-02-16T03:58:38.133Z</published>
    <updated>2020-02-16T03:58:38.133Z</updated>
    
    <content type="html"><![CDATA[<h1 id="将域名从服务器解析到github-page上"><a href="#将域名从服务器解析到github-page上" class="headerlink" title="将域名从服务器解析到github page上"></a>将域名从服务器解析到github page上</h1><ol><li>首先停用掉自己之前的所使用的的子域名</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/n2rrTi.png" alt="figure1"></p><ol><li>然后将列表中关于服务器解析的相关记录去除掉防止出现冲突</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/JzKtQB.png" alt="figure2"></p><ol><li>然后修改github上项目配置将著名设置为++www.stirvezs.com++.</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/jnIjhS.png" alt="figure3"></p><ol><li>修改hexo中的配置文件将url：改为www.strivezs.com</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/5cew7x.png" alt="figure4"></p><ol><li>在域名管理里面添加域名解析<br>主机记录：www 用于www.strivezs.com的访问<br>主机记录：@ 用于strivezs.com的访问</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/LdTBEN.png" alt="figure5"></p><ol><li>使用hexo c&amp;&amp;hexo g &amp;&amp; hexo d将项目重新部署到github上即可。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;将域名从服务器解析到github-page上&quot;&gt;&lt;a href=&quot;#将域名从服务器解析到github-page上&quot; class=&quot;headerlink&quot; title=&quot;将域名从服务器解析到github page上&quot;&gt;&lt;/a&gt;将域名从服务器解析到github pag
      
    
    </summary>
    
    
      <category term="文章页" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/"/>
    
      <category term="Github" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Github/"/>
    
      <category term="域名" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Github/%E5%9F%9F%E5%90%8D/"/>
    
    
      <category term="域名解析" scheme="www.strivezs.com/tags/%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90/"/>
    
      <category term="Github Page" scheme="www.strivezs.com/tags/Github-Page/"/>
    
  </entry>
  
  <entry>
    <title>Learning In RNN Part I</title>
    <link href="www.strivezs.com/2020/01/30/Learning%20In%20RNN%20Part%20I/"/>
    <id>www.strivezs.com/2020/01/30/Learning%20In%20RNN%20Part%20I/</id>
    <published>2020-01-30T10:30:27.662Z</published>
    <updated>2020-01-30T10:30:27.662Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learning-In-RNN"><a href="#Learning-In-RNN" class="headerlink" title="Learning In RNN"></a>Learning In RNN</h1><p><strong>Recurrent Neural Network(RNN)</strong><br>The chinese name is 循环神经网络.</p><h2 id="The-introduction-of-RNN-by-Dr-Mofan-Zhou"><a href="#The-introduction-of-RNN-by-Dr-Mofan-Zhou" class="headerlink" title="The introduction of RNN by Dr.Mofan Zhou"></a>The introduction of RNN by Dr.Mofan Zhou</h2><p>If you want some  dramatic explanations, please check here.<a href="https://www.youtube.com/watch?v=EEtf4kNsk7Q">What is Recurrent Neural NetWorks?</a><br>ps:If you don’t have SSR, you can find the video in BiliBili.</p><p>For the input x(t), we can compute the Y(t) by RNN.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/H7xlDk.png" alt="figure1"></p><p>Then we can call the value S(t) that RNN compute.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/7eJKIX.png" alt="figure2"></p><p>Next RNN will compute the value in X(t+1) and get S(t+1). After that, Y(t+1) is equal S(t) add S(t+1).</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/4pNecb.png" alt="figure3"></p><p>In generally, RNN is look like this:</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/deH7Ml.png" alt="figure4"></p><p> RNN has many structures and can do many things, like classification、regression and so on.</p><h2 id="The-introduction-by-Dr-Hongyi-Li"><a href="#The-introduction-by-Dr-Hongyi-Li" class="headerlink" title="The introduction by Dr.Hongyi Li"></a>The introduction by Dr.Hongyi Li</h2><p> The original video: <a href="https://www.youtube.com/watch?v=xCGidAeyS4M">check here</a></p><h3 id="Example-Application"><a href="#Example-Application" class="headerlink" title="Example Application"></a>Example Application</h3><h4 id="Slot-Filling-填槽"><a href="#Slot-Filling-填槽" class="headerlink" title="Slot Filling(填槽)"></a>Slot Filling(填槽)</h4><p> In many aspects in the life, we can use the slot filling, just like: intelligence customer service、ticket book system and so on.</p><p> <img src="https://gitee.com/zyp521/upload_image/raw/master/MsmWaq.png" alt="figure5"></p><p> In this picture, we need the ticket book system can automatically slot the text in suitable loaction.</p><h5 id="Solving-slot-filling-by-Feedforward-network"><a href="#Solving-slot-filling-by-Feedforward-network" class="headerlink" title="Solving slot filling by Feedforward network?"></a>Solving slot filling by Feedforward network?</h5><p> <strong>Net structure:</strong></p><p> <img src="https://gitee.com/zyp521/upload_image/raw/master/UcqxoK.png" alt="figure10"></p><p> input: a ward (Each word is represented as a vector)</p><p> output: Probability distribution(概率分布) that the input word belonging to the slots.</p><p> ++If we can make our neural network have the ==memory==, so the network will classify if it is a destination or departure.++</p><p>==The way of make a word be represented as a vector==</p><p><strong>1-of-N encoding</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/1LQDzw.png" alt="figure7"></p><p>If we have n words, we can create a vector of length n. And each word will has a value equals one in different index.</p><p><strong>Beyond 1-of-N encoding</strong></p><p>If we have a word that not in our dictionary, we will classify it as other, So we must add a dimension for “other”.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/SlKJF2.png" alt="figure8"></p><p><strong>Word hashing</strong><br>We can also use the word hashing to represent the word. We can make a letter vetcor.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Vz6XVL.png" alt="figure9"></p><h3 id="Recurrent-Neural-NetWork"><a href="#Recurrent-Neural-NetWork" class="headerlink" title="Recurrent Neural NetWork"></a>Recurrent Neural NetWork</h3><p>The output of hidden layer are stored in the memory.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/i9WLXR.png" alt="figure10"></p><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/RSc0zS.png" alt="figure11"></p><p>Presumed:</p><p>ALL the weights are “1”, no bias.</p><p>All the activation functions are lienar.</p><p>Input sequence: <script type="math/tex">\left[ \begin{matrix}1\\1 \end{matrix} \right] \left[ \begin{matrix}1\\ 1 \end{matrix} \right] \left[ \begin{matrix}2 \\ 2 \end{matrix} \right] \dots \dots</script></p><p> First, we must give the initial values of a. Default: 0</p><p> <strong>Step1:</strong></p><p> <img src="https://gitee.com/zyp521/upload_image/raw/master/zsXfrl.png" alt="figure12"></p><p> Input 1 and 1, compute 0 and 1 will get the 2 and 2. And compute 2 and 2 will get 4 and 4. The first output will be 4 and 4, and the memory are 2 and 2.</p><p> <strong>Step2:</strong></p><p> <img src="https://gitee.com/zyp521/upload_image/raw/master/lrOq8c.png" alt="figure13"></p><p> Input 1 and 1, compute 1 and 2 will get 6 and 6, And compute 6 and 6 will get 12 and 12. The second output will be 12 and 12, and the memory are 6 and 6.</p><p> <strong>Step3:</strong></p><p> <img src="https://gitee.com/zyp521/upload_image/raw/master/4aDfln.png" alt="figure14"></p><p> Input 2 and 2, compute 2 and 6 will get 16 and 16, And compute 16 and 16 will get 32 and 32. The second output will be 32 and 32, and the memory are 16 and 16.</p><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><h4 id="Ticket-Book-System-apply-in-RNN"><a href="#Ticket-Book-System-apply-in-RNN" class="headerlink" title="Ticket Book System apply in RNN"></a>Ticket Book System apply in RNN</h4><p><strong>Step1:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/WBXdFc.png" alt="figure15"></p><p>In the figure, arrive is inputed as x1, compute a1 by RNN and store it.</p><p><strong>Step2:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/ogz7xD.png" alt="figure16"></p><p>In this figure, Taipei is inputed as x2, use x2 and a1 to compute a2 and store it.</p><p><strong>Step3:</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Wy8uKU.png" alt="figure17"></p><p>In this figure, on is inputed as x3, use x3 and a2 to compute a 3 and store it.</p><p><strong>So on</strong></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/M9kqVh.png" alt="figure18"></p><p>==Attention:== we are not have only one hidden layer. It can be so many.</p><h4 id="Elman-Network-amp-Jordan-Network"><a href="#Elman-Network-amp-Jordan-Network" class="headerlink" title="Elman Network &amp; Jordan Network"></a>Elman Network &amp; Jordan Network</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Kw2gPZ.png" alt="figure19"></p><p>Elman Network we have talked above, and the Jordan Network is the new one we want to introduce.</p><p>Actually, the differnece between Jordan Network and Elman Network is that Jordan Network make the output to compute with next step computation.</p><h4 id="Bidirectional-双向的-RNN"><a href="#Bidirectional-双向的-RNN" class="headerlink" title="Bidirectional(双向的) RNN"></a>Bidirectional(双向的) RNN</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Iq4InB.png" alt="figure20"></p><p>由上图所示，我们可以同时训练一个正向的循环神经网络，又可以训练一个逆向的神经网络，然后在将他们结果都输入到一个新的隐藏层进行计算产生<script type="math/tex">y^{t}\:\:\:y^{t+1}\:\:\:y^{y+2} \dots</script>.</p><h3 id="Long-Short-term-Memory-LSTM"><a href="#Long-Short-term-Memory-LSTM" class="headerlink" title="Long Short-term Memory(LSTM)"></a>Long Short-term Memory(LSTM)</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/R9BUka.png" alt="figure21"></p><p>The LSTM has three gates, like input gate, forget gate, output gate.</p><p>For all gates, they have own neural network that can learning by themselves to decide how to control the Gate.</p><p>If the output of other part of the network want to input the memory cell, it must pass the input gate. And input gate also be controled by other part of the network. This action can study by itself, it can decide when to open the input gate.</p><p>By the way, the output gate and forget gate also have similar structure.</p><p><strong>Sepcial Neuron(特殊神经元):</strong></p><ul><li>4 inputs</li><li>1 output</li></ul><p>4 input:</p><ul><li>Other part of the network of Input Gate</li><li>Signal control the input gate</li><li>Signal control the output gate</li><li>Signal control the forget gate</li></ul><p>1 output:</p><ul><li>Other part of the network of Output Gate</li></ul><p>++The LSTM can remember many memory cells in long time.++</p><h4 id="Other-expression"><a href="#Other-expression" class="headerlink" title="Other expression"></a>Other expression</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/uMcAkq.png" alt="figure21"></p><p>==Activation funcion f is usually a sigmoid function.==</p><p>The sigmoid function can support between 0 and 1. <strong>0 stand for gate closed, 1 symbolic gate opened.</strong> Mimic open and close gate.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/cfRYnW.png" alt="figure22"></p><script type="math/tex; mode=display">g(z)f(z_{i}) = g(z)\:multiply\: f(z_{i})</script><script type="math/tex; mode=display">c\:multiply\:f(z_{f}) = cf(z_{f})</script><script type="math/tex; mode=display">c^{'}=g(z)g(z_{i})+cf(z_{f})</script><script type="math/tex; mode=display">a = h(c')\:multiply\:f(z_{0})</script><h4 id="LSTM-Example"><a href="#LSTM-Example" class="headerlink" title="LSTM - Example"></a>LSTM - Example</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/RrkPFk.png" alt="figure23"></p><h5 id="Init"><a href="#Init" class="headerlink" title="Init:"></a><strong>Init:</strong></h5><ul><li>one LSTM cell Memory</li><li>3 dimension input</li><li>1 dimension output</li></ul><h5 id="Condition"><a href="#Condition" class="headerlink" title="Condition:"></a><strong>Condition:</strong></h5><ul><li>When <script type="math/tex">x_{2}=1</script>, add the numbers of <script type="math/tex">x_{1}</script> into the memory</li><li>When <script type="math/tex">x_{2}=-1</script>, reset the memory</li><li>When <script type="math/tex">x_{3}=1</script>, output the number in the memory.</li></ul><h5 id="Process"><a href="#Process" class="headerlink" title="Process:"></a><strong>Process:</strong></h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/aBOGRx.png" alt="figure24"></p><p><strong>step1:</strong></p><p>cell memory=0, <script type="math/tex">x_{1}=1\:\:x_{2}=0\:\:x_{3}=0</script> </p><p><strong>step2:</strong></p><p>cell memory=0，<script type="math/tex">x_{1}=3\:\:x_{2}=1\:\:x_{3}=0</script>, because of <script type="math/tex">x_{2}=1</script> , add the numbers of <script type="math/tex">x_{1}</script> into the cell memory.</p><p><strong>step3:</strong></p><p>cell memory=0, <script type="math/tex">x_{1}=2\:\:x_{2}=0\:\:x_{3}=0</script>, no action</p><p><strong>step4:</strong></p><p>cell memory=3,<script type="math/tex">x_{1}=4\:\:x_{2}=1\:\:x_{3}=0</script>,add the number of <script type="math/tex">x_{1}=4</script> into the memory(3+4=7)</p><p><strong>step5:</strong></p><p>cell memory=7,<script type="math/tex">x_{1}=2\:\:x_{2}=0\:\:x_{3}=0</script>, no action</p><p><strong>step6:</strong></p><p>cell memory=7,<script type="math/tex">x_{1}=1\:\:x_{2}=0\:\:x_{3}=1</script>, <script type="math/tex">x_{3}=1</script> output the number in the memory, y=7</p><p><strong>step7:</strong></p><p>cell memroy=7,<script type="math/tex">x_{1}=3\:\:x_{2}=-1\:\:x_{3}=0</script>, <script type="math/tex">x_{2}=-1</script> reset the memory, make the cell memory equal 0</p><p><strong>step8:</strong></p><p>cell memmory=0,<script type="math/tex">x_{1}=6\:\:x_{2}=1\:\:x_{3}=0</script>, <script type="math/tex">x_{2}=1</script> add the number of <script type="math/tex">x_{1}</script> into the memory, cell memory=6(0+6=6)</p><p><strong>step9:</strong></p><p>cell mempry=6,<script type="math/tex">x_{1}=1\:\:x_{2}=0\:\:x_{3}=1</script>, <script type="math/tex">x_{3}=1</script> output the number in the memory, y=6</p><h4 id="Other-Example"><a href="#Other-Example" class="headerlink" title="Other Example"></a>Other Example</h4><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Ngl75m.png" alt="figure25"></p><h5 id="Init-1"><a href="#Init-1" class="headerlink" title="Init"></a>Init</h5><ul><li>four input</li><li>one output</li><li>cell memory=0</li><li>every number of line represent weight</li></ul><h5 id="Process-1"><a href="#Process-1" class="headerlink" title="Process"></a>Process</h5><p><strong>step1:</strong></p><p>for <script type="math/tex">x_{1}=3,x_{2}=1,x_{3}=0</script></p><p>Input=3×1+1×0+0×0+1×0=3</p><p>Input Gate=3×0+1×100+0×0+1×(-10)=90≈1</p><p>Forget Gate=3×0+1×100+0×0+1×10=110≈1</p><p>Output Gate=3×0+1×0+0×100+1×(-10)=-10≈0</p><p>Because outputgate=0 close the output gate, so y=0. And forget gate=1 add the number to cell memory, so cell memory=3.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/JA1A62.png" alt="figure26"></p><p><strong>step2:</strong></p><p>for <script type="math/tex">x_{1}=4,x_{2}=1,x_{3}=0</script></p><p>Input=4×1+1×0+0×1+1×0=4</p><p>Input Gate=4×0+1×100+0×0+1×(-10)=90≈1</p><p>Forget Gate=4×0+100×1+0×0+10×1=110≈1</p><p>Output Gate=4×0+1×0+100×0+1×(-10)=-10≈0</p><p>Because outputgate=0 close the output gate, so y=0. And forget gate=1 add the number to cell memory, so cell memory=7.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/XaaX7E.png" alt="figure27"></p><p><strong>step3:</strong></p><p>for <script type="math/tex">x_{1}=2,x_{2}=0,x_{3}=0</script></p><p>Input=2×1+0×0+0×1+1×0=2</p><p>Input Gate=2×0+0×100+0×0+1×(-10)=-10≈0</p><p>Forget Gate=2×0+100×0+0×0+10×1=10≈1</p><p>Output Gate=2×0+0×0+100×0+1×(-10)=-10≈0</p><p>Because inputgate gate=0 close the input gate,so input equal 0, outputgate=0 close the output gate, so y=0. And forget gate=1 add the number to cell memory, so cell memory=7.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/TwEYUM.png" alt="figure28"></p><p><strong>step4:</strong></p><p>for <script type="math/tex">x_{1}=1,x_{2}=0,x_{3}=1</script></p><p>Input=1×1+0×0+1×0+1×0=1</p><p>Input Gate=1×0+0×100+1×0+1×(-10)=-10≈0</p><p>Forget Gate=1×0+100×0+1×0+10×1=10≈1</p><p>Output Gate=1×0+0×0+100×1+1×(-10)=90≈1</p><p>Because inputgate gate=0 close the input gate,so input equal 0, outputgate=1 open the output gate, so y=7. And forget gate=1 add the number to cell memory, so cell memory=7.</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/WDb4wS.png" alt="figure29"></p><h4 id="Original-NetWork"><a href="#Original-NetWork" class="headerlink" title="Original NetWork"></a>Original NetWork</h4><h5 id="Simply-replace-the-neurons-with-LSTM"><a href="#Simply-replace-the-neurons-with-LSTM" class="headerlink" title="Simply replace the neurons with LSTM"></a>Simply replace the neurons with LSTM</h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/iRUofA.png" alt="figure30"></p><p>replace neurons: </p><p>enter each group of x into the corresponding gate</p><p>4 time of parameters</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/tPL86E.png" alt="figure31"></p><h5 id="Comprehend-cell-memory-deeply"><a href="#Comprehend-cell-memory-deeply" class="headerlink" title="Comprehend cell memory deeply"></a>Comprehend cell memory deeply</h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/DdnHMP.png" alt="figure32"></p><p>Let <script type="math/tex">x^{t}</script> multiply a vector to get <script type="math/tex">z^{f}\:\:z^{i}\:\:z\:\:z^{o}</script>.</p><p>Each of them(<script type="math/tex">z^{f}\:\:z^{i}\:\:z\:\:z^{o}</script>) to be used as input vector.</p><h6 id="Simplify-Structure"><a href="#Simplify-Structure" class="headerlink" title="Simplify Structure"></a>Simplify Structure</h6><p><img src="https://gitee.com/zyp521/upload_image/raw/master/k4eGul.png" alt="figure33"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/801t0i.png" alt="figure34"></p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/TNudQf.png" alt="figure35"></p><h5 id="Multiple-layer-LSTM"><a href="#Multiple-layer-LSTM" class="headerlink" title="Multiple-layer LSTM"></a>Multiple-layer LSTM</h5><p><img src="https://gitee.com/zyp521/upload_image/raw/master/0STWjj.png" alt="figure36"></p><p>This is quite standard now, and don’t worry if you cannot understand this, Keras can handle it.(Kearas supports “LSTM”,”GRU”,”SimpleRNN” layers)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Learning-In-RNN&quot;&gt;&lt;a href=&quot;#Learning-In-RNN&quot; class=&quot;headerlink&quot; title=&quot;Learning In RNN&quot;&gt;&lt;/a&gt;Learning In RNN&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Recurrent 
      
    
    </summary>
    
    
      <category term="文章页" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/"/>
    
      <category term="Python" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/"/>
    
      <category term="Machine Learning" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/Machine-Learning/"/>
    
      <category term="Neural NetWork" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/Machine-Learning/Neural-NetWork/"/>
    
    
      <category term="Python" scheme="www.strivezs.com/tags/Python/"/>
    
      <category term="Machine Learning" scheme="www.strivezs.com/tags/Machine-Learning/"/>
    
      <category term="RNN" scheme="www.strivezs.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>五险一金</title>
    <link href="www.strivezs.com/2020/01/24/%E4%BA%94%E9%99%A9%E4%B8%80%E9%87%91/"/>
    <id>www.strivezs.com/2020/01/24/%E4%BA%94%E9%99%A9%E4%B8%80%E9%87%91/</id>
    <published>2020-01-24T04:02:44.513Z</published>
    <updated>2020-01-24T04:02:44.513Z</updated>
    
    <content type="html"><![CDATA[<h1 id="五险一金"><a href="#五险一金" class="headerlink" title="五险一金"></a>五险一金</h1><h2 id="综合概述"><a href="#综合概述" class="headerlink" title="综合概述"></a>综合概述</h2><h3 id="五险"><a href="#五险" class="headerlink" title="五险"></a>五险</h3><p><img src="https://gitee.com/zyp521/upload_image/raw/master/M87sO4.png" alt="figure1"></p><p>五险：</p><ul><li>养老保险</li><li>医疗保险</li><li>生育保险</li><li>工伤保险</li><li>失业保险</li></ul><p>通常单位和个人都需要缴纳，而且缴纳的比例是不同的。</p><p>其中，单位缴纳的资金进入社会统筹账户，个人缴纳的资金进入个人账户。</p><p>++不同地方的缴纳比例略有不同，一般来说：++</p><ol><li><strong>医疗保险：</strong> 个人担负比例为工资的2%，单位缴纳比例为工资的7%</li><li><strong>养老保险：</strong> 个人担负比例为工资的8%，单位缴纳比例为工资的16%</li><li><strong>工伤保险：</strong> 单位全额担负，缴纳比例为工资的1%</li><li><strong>生育保险：</strong> 单位全额担负，缴纳比例为工资的1%</li><li><strong>失业保险：</strong> 个人担负比例为工资的0.3%，单位缴纳比例为工资的0.7%</li></ol><p>总的下来就是，==在全部的社保里，个人缴纳全部比例是11%左右，工资缴纳全部比例是工资的25%左右。==</p><h3 id="一金"><a href="#一金" class="headerlink" title="一金"></a>一金</h3><p>一金：住房公积金</p><p>根据《住房公积金管理条例》规定，公积金缴费最低比例不能低于职工工资的5%，最高不超过12%，区间内可以由==单位自主确定==缴存比例。</p><h3 id="举一个例子"><a href="#举一个例子" class="headerlink" title="举一个例子"></a>举一个例子</h3><p>假如企业为职工小A开出6000元的工资，那么小A个人的具体社交缴费明细如下：</p><ol><li><strong>医疗保险：</strong> 120元，<strong>养老保险：</strong> 480元，<strong>失业保险：</strong> 18元，<strong>公积金：</strong> 720元</li><li><strong>工伤保险：</strong> 60元(单位全额担负)，<strong>生育保险：</strong> 60元(单位全额担负)</li></ol><p><strong>那么，实际发放到小A银行卡的工资，即到手工资为：</strong> 6000-120-480-18-720=4662元</p><h3 id="根据一个例子解读社会现象"><a href="#根据一个例子解读社会现象" class="headerlink" title="根据一个例子解读社会现象"></a>根据一个例子解读社会现象</h3><h4 id="两种现象："><a href="#两种现象：" class="headerlink" title="两种现象："></a>两种现象：</h4><ol><li>一些公司社保缴费基数不按照实际工资缴费</li><li>一些公司公积金根本不缴纳，或者按照缴费最低比例5%缴纳。</li></ol><p>开始测算，某公司员工平均月工资5000， 下面有两种算法：</p><p><strong>第一种算法：</strong> 公司比较厚道，盈利不错，经济状况好，员工工资5000，社保缴费基数和公积金基数均按实际工资来进行缴纳，即按照5000计算，其中公积金按最高基数12%缴纳。</p><p>那么每月一名员工的==人力成本=员工工资+社保里公司为员工缴纳的部分+公积金里公司为员工缴纳的部分== = 5000 + 5000 <em> 0.25+5000 </em> 0.12=6850元</p><p><strong>第二种算法：</strong><br>经济大形势不好，盈利较差，或者公司不那么厚道，员工工资5000，但社保缴费基数和公积金基数均按最低缴费基数来进行缴纳，按基数3000计算，其中公积金比例，按最低基数5%来缴纳。</p><p>那么每月一名员工的==人力成本=员工工资+社保里公司为员工缴纳的部分+公积金里公司为员工缴纳的部分== =5000+3000 <em> 0.25+3000 </em> 0.05=5900元</p><p><strong>小结</strong></p><p>第一种算法和第二种算法比较，后者公司一个人一个月可节省950元的费用。</p><p>按小公司，有20名员工，那么一年即可节省资金=950 <em> 20 </em> 12 =22.8万元。这比费用对一个小公司来说是一笔不小的开支了。</p><p>但对员工来说，便没那么合算了，不说养老金，养老保险目前执行的是”长缴多得，多较多”的原则。</p><p><strong>所以，目前一个公司，社保和公积金的缴纳水平，可以一定程度上反应公司的经营水平和盈利状况。</strong></p><h2 id="第一部分：失业保险"><a href="#第一部分：失业保险" class="headerlink" title="第一部分：失业保险"></a>第一部分：失业保险</h2><p><strong>失业金领取条件，需要满足以下三个条件:</strong></p><ol><li>失业前用人单位和本人已经缴纳失业保险累计满一年的；</li><li>非因本人意愿中断就业的；</li><li>已经办理失业登记，并有求职要求的</li></ol><p>举个例子，“企业破产、倒闭了，我被企业开除了”可不可以领取，答案是可以领。但是主动离职跳槽是不可以领取的。</p><h3 id="待遇内容"><a href="#待遇内容" class="headerlink" title="待遇内容"></a>待遇内容</h3><ol><li>按月领取的失业保险金，领取失业保险金的期限有以下规定。（缴费1-5年，最长领12个月；缴费5-10年，最长领18个月；缴费10年以上，最长领24个月）</li><li>享受失业保险金期间的医疗补助，住院可以报销医疗费用。</li><li>失业人员，加入在领取失业保险金期间死亡的亲属可以领取丧葬补助金和家属抚恤金。</li></ol><p><strong>各地不听，大概为失业保险关系所在地最低工资标砖的70%-90%，按月发放。</strong></p><h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a><strong>小结：</strong></h3><p>相对于其他社保项目而言，获取事业保险给付的难度是比较大的。但聊胜于无，等真正失业了，每一笔资金都很重要。</p><h2 id="工伤保险"><a href="#工伤保险" class="headerlink" title="工伤保险"></a>工伤保险</h2><p>工伤保险，简单来说就是在工作期间受伤了或者得了==职业病==，获得响应医疗救助和相应的经济步长的保险。</p><h3 id="工伤判定条件"><a href="#工伤判定条件" class="headerlink" title="工伤判定条件"></a>工伤判定条件</h3><ol><li>在工作时间和工作场所内，收到事故伤害的。</li><li>患法律规定职业病的。</li><li>在上下班途中，收到非本人主要责任的交通事故的</li><li>在抢险救灾等维护国家利益中受到伤害的</li><li>职工原在军队服役，因公负伤，到用人单位旧伤复发的。</li></ol><p><strong>注意：</strong> 上下班途中，若是职工自身原因或者主要责任导致事故发生的，不按工伤处理。</p><h4 id="工伤保险待遇"><a href="#工伤保险待遇" class="headerlink" title="工伤保险待遇"></a>工伤保险待遇</h4><ol><li>工伤医疗期间待遇：医疗费、康复费等7项</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/vW9Ae1.jpg" alt="figure2"></p><ol><li>在伤残评定结果出来之后，根据1级到10级伤残级别不同，可以领取伤残步长7-27个月工资：</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/8CXWDn.jpg" alt="figure3"></p><ol><li>1级到6级，有相应的工伤医疗终结后的待遇，根据伤残级别不同，补发伤残津贴和生活护理；</li><li>因工死亡补偿待遇</li></ol><p><img src="https://gitee.com/zyp521/upload_image/raw/master/Sg0neO.jpg" alt="figure4"></p><p>工伤申请需要的材料一般分为：基本资料和补充资料。具体详情请根据规定准备。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>如果单看赔偿项目，工伤保险的保障可以说是非常全面了，从伤残津贴、治疗费、误工费、护理费等，几乎能想到的损失都有补偿。</p><p>但他的局限性也很明显，只赔偿工伤的情形，而无论是意外还是疾病，很多都是在工作场合之外发生，这时候就需要用到社保中的医疗保险了。</p><h2 id="医疗保险"><a href="#医疗保险" class="headerlink" title="医疗保险"></a>医疗保险</h2><p>++首先说明一点，很多地区，医疗保险的最高报销金额，与社保连续缴费时间有关。++</p><h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><p>职工在2017年1月开始上班，1月开始缴纳社保，2月因特殊原因，断了社保。</p><p>3月开始正常缴纳，并补上了2月的社保，后续几月开始享受医疗保险待遇，医疗保险的最高报销金额又是多少呢？</p><p>简单表格：</p><p><img src="https://gitee.com/zyp521/upload_image/raw/master/nFVtMD.jpg" alt="figure5"></p><h4 id="第二点："><a href="#第二点：" class="headerlink" title="第二点："></a><strong>第二点：</strong></h4><p>我国现阶段的医疗保险制度是以“基本医疗保险”为主题，各种形式的补充医疗保险为补充。通常所说的医保，指的是“基因医疗保险”。</p><p>基本医疗保险有包括城镇职工基本医疗保险、城乡居民基本医疗保险。（不可同时参保）</p><p>==不同人的参保范围如下：==</p><ol><li>当地行政区域内的职工和当地灵活就业人员，可以参保城镇职工基本医疗保险，一般个人按工资的2%缴纳；</li><li>城镇居民和乡村居民、学生等，参保城乡居民基本医疗保险，一年缴费一次。</li></ol><p>++在这里特别指出新生婴儿，在出生后即可申请办理社保卡，参加城乡居民基本医疗保险，享受医疗报销++</p><h4 id="第三点："><a href="#第三点：" class="headerlink" title="第三点："></a><strong>第三点：</strong></h4><p>医保的报销范围，简述为两定点、三目录：<br>即参保人在定点医院和定点药店发生的，符合++基本医疗保险目录、诊疗项目范围目录、医疗服务设施范围目录以及国家、省、市的其他的规定的医疗费用++，按规定由基本医疗保险基金支付。</p><p>所以，想要医保报销的金额多：</p><ol><li>务必选择医保定点医院和药店</li><li>另外，用药时，可以提前告知一声，尽量使用医保用药目录内的药品。</li></ol><h4 id="第四点："><a href="#第四点：" class="headerlink" title="第四点："></a><strong>第四点：</strong></h4><p>之前咱们说的，退休后不用继续医保缴费，后续终身享受医保报销待遇，是有前提条件的。==需要退休前有足够的医保缴费年限。==</p><h2 id="养老保险"><a href="#养老保险" class="headerlink" title="养老保险"></a>养老保险</h2><p><strong>通俗说明：</strong>养老保险，简单来说，就是在工作期间，自己和工作单位提前每个月交养老保险费，为以后养老做好积累。</p><h3 id="养老保险怎么交？"><a href="#养老保险怎么交？" class="headerlink" title="养老保险怎么交？"></a>养老保险怎么交？</h3><p><strong>职工养老保险，是单位和个人各自缴纳一部分。</strong></p><p>其中用人单位按照缴费基数 ++不超过20%++ 缴费，交的钱进入统筹账户；职工个人按照缴费基数的 ++8%++ 缴纳，交的钱进入个人账户。</p><h4 id="补充：何为缴费基数？"><a href="#补充：何为缴费基数？" class="headerlink" title="补充：何为缴费基数？"></a>补充：何为缴费基数？</h4><p>按照现行政策，缴费基数工资为职工本人上一年度的平均工资，包括工资、将近、津贴，补贴等收入。另外，++月平均工资超过当地职工平均工资300%以上的部分，不计入个人缴费工资基数；低于当地职工平均工资60%的，按照60%计算缴费工资基数。++</p><h3 id="退休有哪些可享受的养老待遇？"><a href="#退休有哪些可享受的养老待遇？" class="headerlink" title="退休有哪些可享受的养老待遇？"></a>退休有哪些可享受的养老待遇？</h3><ol><li>按月领取养老金</li><li>死亡后，医嘱可以领取丧葬补助金和抚恤金</li><li>++参与每年的养老保险待遇上涨。++</li></ol><p>最后一条看似简单，其实非常重要，由于社会上职工工资的上涨，物价的上涨，通货膨胀等因素，钱会越来越贬值。</p><p>所以，国家建立了养老金的调整机制，每年提高养老保险的待遇水平。<strong>目前，养老金已实现15年连续增长。</strong></p><h3 id="养老金领取条件："><a href="#养老金领取条件：" class="headerlink" title="养老金领取条件："></a>养老金领取条件：</h3><ol><li>职工达到法定的退休年龄</li><li>养老保险累积缴费年限满15年</li><li>已经办理退休手续。</li></ol><p>==只有同时满足了这三个条件以后，才可以领取养老保险==</p><h3 id="特殊说明"><a href="#特殊说明" class="headerlink" title="特殊说明"></a>特殊说明</h3><ol><li>++缴满15年只是退休后享受养老金待遇的最低年限要求，缴费15年还是缴费30年，会直接影响退休后的养老金待遇++，在经济能力允许的情况下，缴费年限能交长一点，尽量交长一点。</li><li>达到法定退休年龄时累积缴费不足15年的，可以缴费至15年后，按月领取基本养老金；也可以转入新型农村社会养老保险或者是城镇居民社会养老保险，按照国家规定享受相应的养老保险待遇。</li></ol><h3 id="怎么计算养老保险金"><a href="#怎么计算养老保险金" class="headerlink" title="怎么计算养老保险金"></a>怎么计算养老保险金</h3><p>建议自行查询了。</p><h2 id="生育保险"><a href="#生育保险" class="headerlink" title="生育保险"></a>生育保险</h2><h3 id="缴纳生育保险，职工可以享受哪些待遇？"><a href="#缴纳生育保险，职工可以享受哪些待遇？" class="headerlink" title="缴纳生育保险，职工可以享受哪些待遇？"></a>缴纳生育保险，职工可以享受哪些待遇？</h3><p>首先说明的是，无论女职工将来妊娠的情况如何，均可以按照规定得到补偿。(也就是说无论戴尔存货与否都可以享受相关待遇)</p><p>具体来说，生育保险待遇主要分为是三个方面：<strong>产假</strong>，<strong>生育医疗费</strong>和<strong>生育津贴</strong>。</p><h3 id="产假怎么计算："><a href="#产假怎么计算：" class="headerlink" title="产假怎么计算："></a>产假怎么计算：</h3><ol><li>基本产假98天，其中产前可以休假15天；</li><li>生育时遇到有难产金和剖腹产的，可增加产假15天；</li><li>生育多胞胎，每多生育1个婴儿，增加产假15天；</li><li>怀孕不满4个月流产的，根据医务部门的意见，给予15天到30天的产假；</li><li>怀孕4个月以上流产的，给予42天产假。</li><li>要注意的是，++产假为连续假期，包括周六周日、法定节假日等++</li></ol><h3 id="生育医疗费可以报销哪一部分的钱"><a href="#生育医疗费可以报销哪一部分的钱" class="headerlink" title="生育医疗费可以报销哪一部分的钱"></a>生育医疗费可以报销哪一部分的钱</h3><ol><li>含产前检查费用；</li><li>女职工生育的检查费、接生费、手术费、住院费和药费，由生育保险基金支付；</li><li>超出额定规定的医疗业务费和药费，由职工个人负担；</li><li>女职工生育出院后，因生育引起疾病的医疗费，由生育保险基金支付；</li><li>其他疾病的医疗费，按照医疗保险待遇的规定办理。</li></ol><h3 id="生育津贴能领多少钱？"><a href="#生育津贴能领多少钱？" class="headerlink" title="生育津贴能领多少钱？"></a>生育津贴能领多少钱？</h3><p>按照职工所在用人单位上年度职工月平均工资除以30天乘以产假天数计发。</p><p><strong>计算公式：</strong> 生育津贴=本单位人均社保缴费工资 / 30(天) * 假期天数</p><p>ps： 流产也能领取生育津贴</p><h3 id="举个例子-1"><a href="#举个例子-1" class="headerlink" title="举个例子"></a>举个例子</h3><p>员工正常婚育，剖腹产，生育了双胞胎，社保缴费基数按6000计算，咱们来算一下该员工的产假时间和生育津贴：</p><ol><li>假期天数=98+15+15=128</li><li>生育津贴=6000/30*128=25600元</li><li></li></ol><h3 id="特殊说明：生育保险和男职工有关吗？"><a href="#特殊说明：生育保险和男职工有关吗？" class="headerlink" title="特殊说明：生育保险和男职工有关吗？"></a>特殊说明：生育保险和男职工有关吗？</h3><p>即男职工正常在职，连续缴纳生育保险，但棋子未缴纳生育保险怎么报销？</p><p><strong>使用前提条件：</strong> 男职工连续缴满10个月，且其配偶未参加职工医保、居民医保。</p><p><strong>享受待遇：</strong> </p><ol><li>生育医疗费用：按“在职女职工”费用标准的50%享受</li><li>产前检查费</li></ol><p><strong>办理流程：</strong><br>先自己自费结算所有费用，再携带申请材料到医保中心申报，最后待遇打给个人。</p><p><strong>特殊说明：</strong>男女职工都可享受计划生育手术费，包括宫内节育器、流产术、引产术、绝育及复通术所发生的医疗费用。</p><h2 id="住房公积金"><a href="#住房公积金" class="headerlink" title="住房公积金"></a>住房公积金</h2><p>买房、装修、租房、退休都可以提取住房公积金，也可以在购买商品房时享受更低的住房贷款利息，需要提供相关证明。公司和你缴纳同等数额，最终全部归个人所有。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;五险一金&quot;&gt;&lt;a href=&quot;#五险一金&quot; class=&quot;headerlink&quot; title=&quot;五险一金&quot;&gt;&lt;/a&gt;五险一金&lt;/h1&gt;&lt;h2 id=&quot;综合概述&quot;&gt;&lt;a href=&quot;#综合概述&quot; class=&quot;headerlink&quot; title=&quot;综合概述&quot;&gt;&lt;/a
      
    
    </summary>
    
    
      <category term="社保" scheme="www.strivezs.com/categories/%E7%A4%BE%E4%BF%9D/"/>
    
    
      <category term="社保" scheme="www.strivezs.com/tags/%E7%A4%BE%E4%BF%9D/"/>
    
  </entry>
  
  <entry>
    <title>Anaconda`s problem of pip</title>
    <link href="www.strivezs.com/2020/01/13/Anaconda%E5%9C%A8%E6%96%B0%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%90%8E%E5%AE%89%E8%A3%85pip%E5%B9%B6%E8%A7%A3%E5%86%B3%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"/>
    <id>www.strivezs.com/2020/01/13/Anaconda%E5%9C%A8%E6%96%B0%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%90%8E%E5%AE%89%E8%A3%85pip%E5%B9%B6%E8%A7%A3%E5%86%B3%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</id>
    <published>2020-01-13T08:09:08.493Z</published>
    <updated>2020-01-13T08:09:08.493Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Anaconda-s-problem-of-pip"><a href="#Anaconda-s-problem-of-pip" class="headerlink" title="Anaconda`s problem of pip"></a>Anaconda`s problem of pip</h1><h2 id="Anaconda安装pip"><a href="#Anaconda安装pip" class="headerlink" title="Anaconda安装pip"></a>Anaconda安装pip</h2><p><strong>步骤</strong></p><ol><li>在对应的环境中打开terminal</li><li>输入conda install setuptools，安装相关的包下载工具</li><li>然后输入 conda install pip 即可安装</li></ol><h2 id="给pip更换国内源"><a href="#给pip更换国内源" class="headerlink" title="给pip更换国内源"></a>给pip更换国内源</h2><p><strong>步骤</strong></p><ol><li>使用windows+R打开运行</li><li>输入%HOMEPATH%</li><li>在用户目录文件夹下创建pip.ini用txt打开（如果有则直接打开）</li><li>更换国内源<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">global</span>]</span><br><span class="line">timeout = <span class="number">10</span> # 设置超时，单位s</span><br><span class="line"><span class="keyword">index</span>-url =  http://mirrors.aliyun.com/pypi/simple/   # 指定优先下载源</span><br><span class="line">extra-<span class="keyword">index</span>-url= http://pypi.douban.com/simple/   # 第二下载源</span><br><span class="line">[install]</span><br><span class="line"><span class="keyword">trusted</span>-host=</span><br><span class="line">    mirrors.aliyun.com</span><br><span class="line">    pypi.douban.com</span><br></pre></td></tr></table></figure></li></ol><h2 id="解决SSL问题"><a href="#解决SSL问题" class="headerlink" title="解决SSL问题"></a>解决SSL问题</h2><p>在更换完国内源之后仍然出现SSL，连接失败问题的话，则给出下述办法。<br><strong>步骤</strong></p><ol><li>找到该地址<strong>D:\Anaconda\pkgs\openssl-1.0.2p-hfa6e2cd_0\Library\bin</strong></li><li>然后将它添加到User的系统环境变量中即可。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Anaconda-s-problem-of-pip&quot;&gt;&lt;a href=&quot;#Anaconda-s-problem-of-pip&quot; class=&quot;headerlink&quot; title=&quot;Anaconda`s problem of pip&quot;&gt;&lt;/a&gt;Anaconda`s 
      
    
    </summary>
    
    
      <category term="文章页" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/"/>
    
      <category term="Python" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/"/>
    
      <category term="Anaconda" scheme="www.strivezs.com/categories/%E6%96%87%E7%AB%A0%E9%A1%B5/Python/Anaconda/"/>
    
    
      <category term="Python" scheme="www.strivezs.com/tags/Python/"/>
    
      <category term="Anaconda" scheme="www.strivezs.com/tags/Anaconda/"/>
    
      <category term="pip" scheme="www.strivezs.com/tags/pip/"/>
    
  </entry>
  
</feed>
